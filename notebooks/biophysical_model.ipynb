{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf70ba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb42f3",
   "metadata": {},
   "source": [
    "# Biophysical model\n",
    "\n",
    "The `multidms` joint model applies primarily to a case where you have deep mutational scanning (DMS) datasets\n",
    "for two or more experimental conditions and are interested in identifying differences (i.e. _shifts_)\n",
    "in mutational effects between conditions. \n",
    "Here we describe the biophysical model of conditional shifts that motivates the approach in this package.\n",
    "\n",
    "We suggest reading the [Otwinowski et al. 2018](https://www.pnas.org/doi/10.1073/pnas.1804015115) paper to understand the approach for modeling global epistasis before reading the rest of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb63fef",
   "metadata": {},
   "source": [
    "## Model overview\n",
    "\n",
    "`multidms` extends the traditional global epistasis model by informing the parameters with multiple DMS experiments under differing experimental _conditions_ (referred to as $h$). Distinct conditions may include non-homologous wildtype sequences between DMS experiments (i.e. SARS-CoV-2 Delta Vs. Omicron spike). However, this approach could also be used for experimental conditions which share homology of the wildtype, but are run with different selection steps. This model makes the assumption that differing conditions should result in _mostly_ the same effect of mutations -- but some _shifts_ in mutational effect due to biological mechanisms (i.e. epistasis). Ultimately, this model was designed to identify those shifts relative to user's chosen _reference_ condition with feature selection via a lasso \"$L_{1}$\" regularization of the shift parameters described in the additive latent phenotype section below.\n",
    "\n",
    "At a high level, the model is a composition of three\n",
    "functions which describe the expected biophysical interactions underlying a given phenotype;\n",
    "(1) $\\phi$, an additive model describing a variant's _latent_ phenotype under a given condition,\n",
    "(2) $g$, a global epistasis model shared by all conditions to disentangle the effects of multiple mutations on the same variant, and\n",
    "(3) $t$, a final output activation function accounting for the expected _lower bound_ on any given variant's phenotype.\n",
    "\n",
    "Concretely, the predicted phenotype for a given variant $v$ under condition $h$ is given by \n",
    "\n",
    "$$\n",
    "\\hat{y}_{v,h} = t_{\\gamma}(g_{\\alpha}(\\phi_{\\beta, S, C_{r}}(v,h))\n",
    "$$\n",
    "\n",
    "Where \n",
    "$\\gamma$, $\\alpha$, $\\beta$, $S$, and $C_{r}$\n",
    "are _free_ parameters inferred from experimental observations during the fitting process. We describe the individual components and their associates parameters in more detail below.\n",
    "\n",
    "**Note** The motivation behind defining an abstract model in terms of its components provides (1) modularity for method testing and development, and (2) multiple options for model components. While there is only a single option for the latent prediction, $\\phi$, we offer a few options _post-latent_ modeling, $g$ and $t$, that encompass the needs of differing research goals and experimental techniques. Generally speaking, the package defaults for these components should be sufficient for most purposes, and in this case feel free to ignore the `multidms.biophysical` module all-together as this functionality is hidden unless explicitly specified during the instantiation of a `MultiDmsModel` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99477fac",
   "metadata": {},
   "source": [
    "## Normalizing observed functional scores using $\\gamma_{h}$ \n",
    "\n",
    "The first consideration is whether observed functional scores are directly comparable between conditions.\n",
    "In context of the model, _Predicted_ functional scores are all directly comparable since all are generated from the same latent space via the same global-epistasis function.\n",
    "However, observed scores may not be comparable in the same way.\n",
    "For instance, a common way to compute functional scores is with log enrichment ratios, normalized so that the wildtype sequence has a value of zero.\n",
    "If the conditions being compared are DMS experiments conducted in the background of different homologs, then each homolog will necessarily have a functional score of zero within its experiment, even if those same homologs would have different functional scores when measured in the same experiment.\n",
    "Thus, log enrichment ratios are not always directly comparable between experiments.\n",
    "Ideally, one or more of the same sequences would be included in the experimental design of DMS libraries to be compared and normalized to the same sequence.\n",
    "However, if there are no such sequences, then it may be possible to computationally estimate how to renormalize scores.\n",
    "\n",
    "To this end, the model includes an additional parameter $\\gamma_h$ for each non-reference condition that allows functional scores, $y'_{v,h}$ from that condition to be renormalized as follows:\n",
    "\n",
    "$$\n",
    "y'_{v,h} = y_{v,h} + \\gamma_h\n",
    "$$\n",
    "\n",
    "where $\\gamma_h$ for the reference condition is locked at zero.\n",
    "There is a theoretical basis for adding $\\gamma_h$ to $y_{v,h}$ if functional scores are log enrichment ratios.\n",
    "As mentioned above, log enrichment ratios are normalized so that the wildtype sequence from a given experiment has a value of zero, according to the formula:\n",
    "\n",
    "$$\n",
    "y_{v,h} = \\log(E_{v,h}) - \\log(E_{\\text{wt},h})\n",
    "$$\n",
    "\n",
    "Thus, adding $\\gamma_d$ to $y_{v,d}$ is akin to renormalizing the log enrichment ratios so that a different sequence has a functional score of zero.\n",
    "In theory, for each non-reference condition, there is a $\\gamma_d$ that renormalizes functional scores to be relative to the wildtype sequence of the reference condition.\n",
    "If these values are not experimentally measured, the model allows $\\gamma_d$ parameters to be fit during optimization, which assumes that the correct $\\gamma_d$ values will give the best model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a42e3",
   "metadata": {},
   "source": [
    "## Additive latent phenotype, $\\phi$\n",
    "\n",
    "For each mutation $m$, the model defines a single mutation effect parameter, $\\beta_{m}$ shared by all conditions.\n",
    "Additionally, the model defines the set of shift parameters, $s_{m,h}$, \n",
    "that quantifies the shift a given mutation's effect relative to some reference condition. \n",
    "Each mutation, for each non-reference condition, is associated with an independent shift parameter.\n",
    "For example, if there exists three total experimental conditions, $h \\in \\{h_{1}, h_{2}$, $h_{3}\\}$, \n",
    "and we define $h_{1}$ to be the _reference_ condition,\n",
    "the model defines two sets of non-reference _shift_ parameters $s_{m, h_{2}}$, $s_{m, h_{3}}$ that may be fit to non-zero values. Note that while a $s_{m, h_{1}}$ does exist for computational and mathemathical coherency, it is locked to $0$ during the fitting procedure and is functionally ignored.\n",
    "\n",
    "Concretely, the latent phenotype of any variant, $v$, from the experimental condition, $h$,\n",
    "is computed like so:\n",
    "\n",
    "$$\n",
    "\\phi(v,h) = c_{r} + \\sum_{m \\in v} (\\beta_{m} + S_{m,h})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $c_{r}$ is the wildtype latent phenotype for the reference condition. \n",
    "* $\\beta_{m}$ is the latent phenotypic effect of mutation $m$ (See the note below), \n",
    "* $s_{m,h}$ is the shift of the effect of mutation $m$ in condition $h$.\n",
    "* $v$ is the set of all mutations relative to the reference wild type sequence including all potential non-identical wildtype mutations that separate condition $h$ from the reference condition.\n",
    "\n",
    "As stated in the overview above, we expect the mutation effect among conditions to largely be the same. By applying a _lasso_ $L_{1}$ regularization term to shift parameters we encourage most $s_{m,h}$ to be zero, while identifying non-zero shifts with confidence. We find that the model is robust for most reasable choices of regularization strength. See the fitting procedure below for more on this.\n",
    "\n",
    "**Note** The $\\beta_m$ variable is defined such that mutations are always relative to the\n",
    "reference condition. For example, if the wild type amino acid at site 30 is an\n",
    "A in the reference condition, and a G in a non-reference condition,\n",
    "then a Y30G mutation in the non-reference condition is recorded as an A30G\n",
    "mutation relative to the reference. This way, each condition informs\n",
    "the exact same parameters, even at sites that differ in wild type amino acid.\n",
    "These are encoded in a `BinaryMap` object, where all sites that are non-identical\n",
    "to the reference are 1's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6416322",
   "metadata": {},
   "source": [
    "## global epistasis, $g$\n",
    "\n",
    "Latent phenotypes as described above give rise to functional scores according to a global-epistasis function.\n",
    "If this function is non-linear, then the model allows mutations to non-additively effect functional scores, helping to account for global epistasis.\n",
    "Here, we'll go into more detail about the options available in `multidms` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8613ea",
   "metadata": {},
   "source": [
    "### Sigmoidal:\n",
    "\n",
    "By default, the global-epistasis function here assumes a sigmoidal relationship between\n",
    "a protein's latent property and it's functional score measured in the experiment\n",
    "(e.g., log enrichment score). Using free parameters, the sigmoid\n",
    "can flexibly conform to an optimal shape informed by the data. \n",
    "Note that this function is independent from the\n",
    "experimental condition from which a variant is observed.\n",
    "\n",
    "The sigmoidal function that relates a given _latent phenotype_, $z$, to its functional score is given by:\n",
    "\n",
    "$$\n",
    "g(z) =  \\frac{\\alpha_{scale}}{1 + e^{-z}} + \\alpha_{bias}\n",
    "$$\n",
    "\n",
    "Where $\\alpha_{scale}$ and $\\alpha_{bias}$ are free parameters defining the range and lower bound of the sigmoid, respectively.\n",
    "\n",
    "Below is an interactive plot showing the effect of the sigmoidal global epistasis as a function of an adjustable $\\alpha_{scale}$, and $\\alpha_{bias}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3e310c",
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-7ca76b8e757449608543347f8946535f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7ca76b8e757449608543347f8946535f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7ca76b8e757449608543347f8946535f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-5df0d8288b8899ccb5d4c64cc03b51be\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"latent phenotype\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"alpha_scale\", \"bind\": {\"input\": \"range\", \"max\": 10, \"min\": 0.1}, \"value\": 5}, {\"name\": \"alpha_bias\", \"bind\": {\"input\": \"range\", \"max\": 5, \"min\": -10}, \"value\": 0}], \"transform\": [{\"calculate\": \"(((1 / (1 + exp((-1 * datum['latent'])))) * alpha_scale) + alpha_bias)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-5df0d8288b8899ccb5d4c64cc03b51be\": [{\"latent\": -10.0}, {\"latent\": -9.797979797979798}, {\"latent\": -9.595959595959595}, {\"latent\": -9.393939393939394}, {\"latent\": -9.191919191919192}, {\"latent\": -8.98989898989899}, {\"latent\": -8.787878787878787}, {\"latent\": -8.585858585858587}, {\"latent\": -8.383838383838384}, {\"latent\": -8.181818181818182}, {\"latent\": -7.979797979797979}, {\"latent\": -7.777777777777778}, {\"latent\": -7.575757575757576}, {\"latent\": -7.373737373737374}, {\"latent\": -7.171717171717171}, {\"latent\": -6.96969696969697}, {\"latent\": -6.767676767676768}, {\"latent\": -6.565656565656566}, {\"latent\": -6.363636363636363}, {\"latent\": -6.161616161616162}, {\"latent\": -5.959595959595959}, {\"latent\": -5.757575757575758}, {\"latent\": -5.555555555555555}, {\"latent\": -5.353535353535354}, {\"latent\": -5.151515151515151}, {\"latent\": -4.94949494949495}, {\"latent\": -4.747474747474747}, {\"latent\": -4.545454545454546}, {\"latent\": -4.343434343434343}, {\"latent\": -4.141414141414142}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.737373737373738}, {\"latent\": -3.5353535353535355}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1313131313131315}, {\"latent\": -2.929292929292929}, {\"latent\": -2.7272727272727275}, {\"latent\": -2.525252525252525}, {\"latent\": -2.3232323232323235}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9191919191919187}, {\"latent\": -1.717171717171718}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3131313131313131}, {\"latent\": -1.1111111111111107}, {\"latent\": -0.9090909090909101}, {\"latent\": -0.7070707070707076}, {\"latent\": -0.5050505050505052}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.10101010101010033}, {\"latent\": 0.10101010101010033}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.5050505050505052}, {\"latent\": 0.7070707070707076}, {\"latent\": 0.9090909090909083}, {\"latent\": 1.1111111111111107}, {\"latent\": 1.3131313131313131}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.7171717171717162}, {\"latent\": 1.9191919191919187}, {\"latent\": 2.121212121212121}, {\"latent\": 2.3232323232323235}, {\"latent\": 2.525252525252524}, {\"latent\": 2.7272727272727266}, {\"latent\": 2.929292929292929}, {\"latent\": 3.1313131313131315}, {\"latent\": 3.333333333333334}, {\"latent\": 3.5353535353535346}, {\"latent\": 3.737373737373737}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.141414141414142}, {\"latent\": 4.3434343434343425}, {\"latent\": 4.545454545454545}, {\"latent\": 4.747474747474747}, {\"latent\": 4.94949494949495}, {\"latent\": 5.1515151515151505}, {\"latent\": 5.353535353535353}, {\"latent\": 5.555555555555555}, {\"latent\": 5.757575757575758}, {\"latent\": 5.9595959595959584}, {\"latent\": 6.161616161616163}, {\"latent\": 6.363636363636363}, {\"latent\": 6.565656565656564}, {\"latent\": 6.767676767676768}, {\"latent\": 6.969696969696969}, {\"latent\": 7.171717171717173}, {\"latent\": 7.373737373737374}, {\"latent\": 7.575757575757574}, {\"latent\": 7.777777777777779}, {\"latent\": 7.979797979797979}, {\"latent\": 8.18181818181818}, {\"latent\": 8.383838383838384}, {\"latent\": 8.585858585858585}, {\"latent\": 8.787878787878789}, {\"latent\": 8.98989898989899}, {\"latent\": 9.19191919191919}, {\"latent\": 9.393939393939394}, {\"latent\": 9.595959595959595}, {\"latent\": 9.7979797979798}, {\"latent\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 10, 100)})\n",
    "\n",
    "slider_s = alt.binding_range(min=0.1, max=10)\n",
    "var_s = alt.param(bind=slider_s, value=5, name=\"alpha_scale\")\n",
    "\n",
    "slider_b = alt.binding_range(min=-10, max=5)\n",
    "var_b = alt.param(bind=slider_b, value=0, name=\"alpha_bias\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=(1 / (1 + alt.expr.exp(-1*alt.datum['latent'])))\n",
    "        * var_s\n",
    "        + var_b\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"latent phenotype\", scale=alt.Scale(domain=[-10, 10])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 10]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_s, var_b)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127046f",
   "metadata": {},
   "source": [
    "### Single-layer neural network epistasis:\n",
    "\n",
    "If you prefer a less constrained shape for global epistasis, we also offer the ability to learn the shape of global epistasis using a single-layer neural network, sometimes referred to as a [multi-layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron). For this option, the user defines a number of units in the singular hidden layer of the model. For each hidden unit, we introduce three parameters (two weights and a bias) to be inferred. All weights are clipped at zero to maintain assumptions of monotonicity in the resulting epistasis function shape.  The network applies a sigmoid activation to each internal unit before a final transformation and addition of a constant gives us our predicted functional score. \n",
    "\n",
    "Given a latent phenotype, $z$, the neural network function can then be defined:\n",
    "\n",
    "$$\n",
    "g(z) = b^{o}+ \\sum_{i}^{n}(\\frac{w^{o}_{i}}{1 + e^{w^{l}_{i}*z + b^{l}_{i}}})\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $n$ is the number of units in the hidden layer.\n",
    "* $w^{l}_{i}$ and $w^{o}_{i}$ are free parameters representing latent and output tranformations, respectively, associated with unit $i$ in the hidden layer of the network. \n",
    "* $b^{l}_{i}$ is a free parameter, as an added bias term to unit $i$.\n",
    "* $b^{o}$ is a constant, singular free parameter.\n",
    "\n",
    "**Note** In the `multidms` API, This behavior is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function `multidms.biophysical.single_layer_nn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cab98f",
   "metadata": {},
   "source": [
    "### Identity (no epistasis):\n",
    "\n",
    "In some scenerios, deep mutational scanning data only contains single-mutation variants to be observed. It then becomes hopeless to learn anything useful about epiststatic effects. In this scenerio, we provide the option to functionally disable any global epistsis modeling by setting $g(z) = z$. \n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function definition `multidms.biophysical.identity_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8e0a9",
   "metadata": {},
   "source": [
    "## Output activation, $t$\n",
    "\n",
    "The commonly reported fold-change metric for functional scores described above falls victim to reported outliers. This is particularly problematic when the starting frequency of a barcoded variant is low. Common solutions to this sensitivity problem include the use of highly multiplexed assays with variant-level barcode replicates, as well simply filtering out low frequency variants. Unfortunatly, even modest filtering thresholds for starting frequency and number of barcode replicates may cut out informative signal for the model. Thus, it's also common for researchers to simply _truncate_ (i.e. _clip_) the functional at some lower bound $l$, where observations below are assumed largely to be outlier.\n",
    "\n",
    "This type of truncation in the data leads to unwanted behavior in our global epistasis model. Put simply, $g$ _learns_ this lower bound, and thus is encouraged to limit it's shape to conform to this lower bound during the fitting process. This behavior is particularly problematic when normalizing the observed functional scores with $\\gamma_{h}$, described above. To provide intuition, consider a scenario where observed functional scores are truncated at a lower bound of -3 across all conditions. If $\\gamma_d$ is fit to -1.0 for one of the non-reference conditions, then the new floor of functional scores will be -4 for that condition, while the floor for the reference condition would still be -3. In this case, the global epistasis function could find itself in a pickle: if it allows predictions to go below -3, it could help model the floor of points in the non-reference condition, but hurt with modeling the floor of points in the reference condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d03fe",
   "metadata": {},
   "source": [
    "### Softplus\n",
    "\n",
    "By default, we avoid this unwanted behavior by applying a final activation on the output of the global epistasis model. In essence, this is a modified _softplus_ activation, ($\\text{softplus}(x)=\\log(1 + e^{x})$) with a _lower bound_ at $l + \\gamma_{h}$, as well as a _ramping_ coefficient, $\\lambda_{\\text{sp}}$. \n",
    "\n",
    "Concretely, if we let $z' = g(\\phi(v,h))$, then the predicted functional score of our model is given by:\n",
    "\n",
    "$$\n",
    "t(z') = \\lambda_{sp}\\log(1 + e^{\\frac{z' - l}{\\lambda_{sp}}}) + l\n",
    "$$\n",
    "\n",
    "Functionally speaking, this truncates scores below a lower bound, while leaving scores above (mostly) unaltered. There is a small range of input values where the function smoothly transitions between a flat regime (where data is truncated) and a linear regime (where data is not truncated). \n",
    "\n",
    "**Note** By default, we recommend leaving the $\\lambda_{sp}$ parameter at it's default value of $0.1$. this ensures a sharp transition between regimes similar to a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) function, but retain the differentible property for gradient based optimization.\n",
    "\n",
    "Below is an interactive plot showing the effect of the modified softplus activation as a function of an adjustable $\\lambda_{sp}$ scaling parameter, and lower bound, $l$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02d0f67",
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a4f405dae86b44a78b4d3c3313a4af83\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a4f405dae86b44a78b4d3c3313a4af83\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a4f405dae86b44a78b4d3c3313a4af83\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-cabdca2257cf20e376d04c62a66e94ee\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 5]}, \"title\": \"global epistasis prediction (z')\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 5]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"lambda_sp\", \"bind\": {\"input\": \"range\", \"max\": 2, \"min\": 0.1}, \"value\": 1}, {\"name\": \"lower_bound\", \"bind\": {\"input\": \"range\", \"max\": 0, \"min\": -10}, \"value\": -3.5}], \"transform\": [{\"calculate\": \"((log((1 + exp(((datum['latent'] - lower_bound) / lambda_sp)))) * lambda_sp) + lower_bound)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-cabdca2257cf20e376d04c62a66e94ee\": [{\"latent\": -10.0}, {\"latent\": -9.848484848484848}, {\"latent\": -9.696969696969697}, {\"latent\": -9.545454545454545}, {\"latent\": -9.393939393939394}, {\"latent\": -9.242424242424242}, {\"latent\": -9.09090909090909}, {\"latent\": -8.93939393939394}, {\"latent\": -8.787878787878787}, {\"latent\": -8.636363636363637}, {\"latent\": -8.484848484848484}, {\"latent\": -8.333333333333334}, {\"latent\": -8.181818181818182}, {\"latent\": -8.030303030303031}, {\"latent\": -7.878787878787879}, {\"latent\": -7.727272727272727}, {\"latent\": -7.575757575757576}, {\"latent\": -7.424242424242424}, {\"latent\": -7.2727272727272725}, {\"latent\": -7.121212121212121}, {\"latent\": -6.96969696969697}, {\"latent\": -6.818181818181818}, {\"latent\": -6.666666666666666}, {\"latent\": -6.515151515151516}, {\"latent\": -6.363636363636363}, {\"latent\": -6.212121212121212}, {\"latent\": -6.0606060606060606}, {\"latent\": -5.909090909090909}, {\"latent\": -5.757575757575758}, {\"latent\": -5.6060606060606055}, {\"latent\": -5.454545454545454}, {\"latent\": -5.303030303030303}, {\"latent\": -5.151515151515151}, {\"latent\": -5.0}, {\"latent\": -4.848484848484849}, {\"latent\": -4.696969696969697}, {\"latent\": -4.545454545454545}, {\"latent\": -4.393939393939394}, {\"latent\": -4.242424242424242}, {\"latent\": -4.090909090909091}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.787878787878788}, {\"latent\": -3.636363636363636}, {\"latent\": -3.4848484848484844}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1818181818181817}, {\"latent\": -3.0303030303030303}, {\"latent\": -2.878787878787879}, {\"latent\": -2.7272727272727266}, {\"latent\": -2.5757575757575752}, {\"latent\": -2.424242424242424}, {\"latent\": -2.2727272727272725}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9696969696969688}, {\"latent\": -1.8181818181818183}, {\"latent\": -1.666666666666666}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3636363636363633}, {\"latent\": -1.212121212121211}, {\"latent\": -1.0606060606060606}, {\"latent\": -0.9090909090909083}, {\"latent\": -0.7575757575757578}, {\"latent\": -0.6060606060606055}, {\"latent\": -0.45454545454545503}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.1515151515151505}, {\"latent\": 0.0}, {\"latent\": 0.15151515151515227}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.45454545454545503}, {\"latent\": 0.6060606060606055}, {\"latent\": 0.7575757575757578}, {\"latent\": 0.9090909090909101}, {\"latent\": 1.0606060606060606}, {\"latent\": 1.2121212121212128}, {\"latent\": 1.3636363636363633}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.6666666666666679}, {\"latent\": 1.8181818181818183}, {\"latent\": 1.9696969696969706}, {\"latent\": 2.121212121212121}, {\"latent\": 2.2727272727272734}, {\"latent\": 2.424242424242424}, {\"latent\": 2.575757575757576}, {\"latent\": 2.7272727272727284}, {\"latent\": 2.878787878787879}, {\"latent\": 3.030303030303031}, {\"latent\": 3.1818181818181817}, {\"latent\": 3.333333333333334}, {\"latent\": 3.4848484848484844}, {\"latent\": 3.6363636363636367}, {\"latent\": 3.787878787878789}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.090909090909092}, {\"latent\": 4.242424242424242}, {\"latent\": 4.3939393939393945}, {\"latent\": 4.545454545454547}, {\"latent\": 4.696969696969697}, {\"latent\": 4.8484848484848495}, {\"latent\": 5.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 5, 100)})\n",
    "\n",
    "slider_lsp = alt.binding_range(min=0.1, max=2)\n",
    "var_lambda_sp = alt.param(bind=slider_lsp, value=1, name=\"lambda_sp\")\n",
    "\n",
    "slider_lb = alt.binding_range(min=-10, max=0)\n",
    "var_lower_bound = alt.param(bind=slider_lb, value=-3.5, name=\"lower_bound\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=alt.expr.log(1 + alt.expr.exp((alt.datum['latent']-var_lower_bound)/var_lambda_sp))\n",
    "        * var_lambda_sp\n",
    "        + var_lower_bound\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"global epistasis prediction (z')\", scale=alt.Scale(domain=[-10, 5])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 5]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_lambda_sp, var_lower_bound)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2110c57",
   "metadata": {},
   "source": [
    "### Identity (no activation):\n",
    "\n",
    "We offer the option to functionally _disable_ this feature in the case where there's no expected floor on the range of fitting data.\n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function definition `multidms.biophysical.identity_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc52e5",
   "metadata": {},
   "source": [
    "## Fitting procedure\n",
    "\n",
    "`multidms` is implimented in _python_ using the [JAX](https://github.com/google/jax) library.\n",
    "This allows for the direct differentiation of the composed model.\n",
    "The [jaxopt](https://jaxopt.github.io/stable/index.html) package is used for effecient optimization of all parameters with [proximal gradient descent](https://en.wikipedia.org/wiki/Proximal_gradient_method).\n",
    "Given DMS training data, The objective is to minimize the difference between _normalized observed_ and _predicted_ functional scores ($y'_{v, h} - \\hat{y}$). We apply a lasso $L_{1}$ penalty to all $s_{m,h}$ parameters for feature selection of high confidence values, and encouraging the rest to be $0$.\n",
    "\n",
    "The total loss on a dataset is computed as the sum of the individual losses for each condition in the dataset. \n",
    "\n",
    "$$\n",
    "L_{\\text{total}} = \\sum_{h} [L_{\\text{fit},h} + L_{\\text{reg},h}]\n",
    "$$\n",
    "\n",
    "conditional loss is then given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_{\\text{fit},h} &= \\frac{\\sum_{v} L_{\\text{Huber}}(y'_{v,h}, t(v,h))}{n_h} \\\\\n",
    "L_{\\text{reg},h} &= \\lambda \\sum_{m} |s_{m,h}|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where; $L_{\\text{Huber}}$ is a Huber loss function and $n_{h}$ is the number of variants in the condition.\n",
    "\n",
    "Dividing the numerator $L_{\\text{fit},h}$ by $n_h$ makes it so that $L_{\\text{fit},h}$ returns the average loss across all variants. Ultimitely, this ensures that each condition contributes equally to $L_\\text{total}$, regardless of the number of variants in that condition.\n",
    "\n",
    "**Note** We find the qualitative results of model fits and their respective shift parameters are quite robust for a reasonable choice of $\\lambda$ applied to the lasso. In other words, this parameter can be set to reflect the user's own preference for [accuracy-simplicity](https://en.wikipedia.org/wiki/Lasso_(statistics)) tradeoff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
