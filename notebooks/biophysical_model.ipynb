{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf70ba23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74def7",
   "metadata": {},
   "source": [
    "# Biophysical model\n",
    "\n",
    "The goal of `multidms` is to jointly infer mutational effects across multiple deep mutational scanning (DMS) experiments, including how much each mutation's effect differs between experiments.\n",
    "We refer to these differences as *shifts*.\n",
    "If the experiments were performed with different homologs of the same protein, a shift would indicate epistasis between the shifted mutation and the amino-acid mutations that separate the homologs.\n",
    "Or, if they were performed with the same wildtype protein under different selective conditions (e.g., selection for viral entry using different but related host receptors), shifts would indicate condition-specific effects.\n",
    "Ultimately, this model was designed to identify those shifts relative to user’s chosen _reference condition_ with feature selection via a lasso “$L_1$” regularization of the shift parameters described in the additive latent phenotype section below.\n",
    "\n",
    "`multidms` is compatible with DMS data that have the following characteristics.\n",
    "First, the data must report a functional score (e.g., log enrichment ratio) for each variant from each DMS experiment, where a variant constitutes a unique gene sequence covering the entire mutagenized region.\n",
    "Thus, the deep-sequencing data must resolve complete haplotypes.\n",
    "Second, most mutations must be seen in multiple unique variants per experiment, as this number is the basis by which shifts are regularized (see below).\n",
    "This second requirement is often met in DMS libraries with multiple mutations per variant, as long as each mutation occurs in multiple genetic backgrounds, or in libraries with one mutation per variant, as long as each variant is uniquely barcoded and individual mutations are found in the background of multiple barcodes. Given input data from one or more experiments, `multidms` fits to all the data and provides:\n",
    "(1) mutational effects across all experiments, $\\beta_m$\n",
    "(2) how effects are shifted between experiments, $\\Delta_{d, m}$, and \n",
    "(3) A model to predict the functional score of any given variant.\n",
    "\n",
    "**Note**: We suggest reading the [Otwinowski et al. 2018](https://www.pnas.org/doi/10.1073/pnas.1804015115) paper to understand the approach for modeling global epistasis before reading the rest of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb42f3",
   "metadata": {},
   "source": [
    "## Joint-model composition\n",
    "\n",
    "At a high level, the model is a composition of three\n",
    "functions which describe the expected biophysical interactions underlying a given phenotype;\n",
    "(1) $\\phi$, an additive model describing a variant's _latent_ phenotype under a given condition,\n",
    "(2) $g$, a global epistasis model shared by all conditions to disentangle the effects of multiple mutations on the same variant, and\n",
    "(3) $t$, an _optional_ final output activation function which can account for variant functional scores which have been clipped at some lower bound _prior_ to using `multidms`. \n",
    "\n",
    "Concretely, the predicted phenotype for a given variant $v$ under condition $d$ is given by \n",
    "\n",
    "$$\n",
    "\\hat{y}_{v, d} = t_{\\gamma_{d}}(g_{\\alpha}(\\phi_{d, \\beta, \\Delta}(v))\n",
    "$$\n",
    "\n",
    "Where \n",
    "$\\gamma$, $\\alpha$, $\\beta$, and $\\Delta$\n",
    "are _free_ parameters inferred from experimental observations during the fitting process. We describe the individual components and their associated parameters in more detail below.\n",
    "\n",
    "**Note** The motivation behind defining an abstract model in terms of it's components are (1) modularity for method testing and development, and (2) the ability to provide multiple options for model components. While there is only a single option for the latent prediction, $\\phi$, we offer a few options _post-latent_ modeling, $g$ and $t$, that encompass the needs of differing research goals and experimental techniques. Generally speaking, the package defaults for these components should be sufficient for most purposes, and in this case feel free to ignore the `multidms.biophysical` module all-together as this functionality is hidden unless explicitly specified during the instantiation of a `MultiDmsModel` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a42e3",
   "metadata": {},
   "source": [
    "## latent phenotype\n",
    "\n",
    "For each mutation $m$, the model defines a single mutation effect parameter, $\\beta_{m}$ shared by all conditions.\n",
    "Additionally, the model defines the set of shift parameters, $\\Delta_{d,m}$, \n",
    "that quantifies the shift a given mutation's effect relative to some reference condition. \n",
    "Each mutation, for each non-reference condition, is associated with an independent shift parameter.\n",
    "For example, if there exists three total experimental conditions, $d \\in \\{d_{1}, d_{2}$, $d_{3}\\}$, \n",
    "and we define $d_{1}$ to be the _reference_ condition,\n",
    "the model defines two sets of (non-reference) _shift_ parameters $\\Delta_{d_{2}, m}$, $\\Delta_{d_{3}, m}$ that may be fit to non-zero values. Note that while a $s_{m, h_{1}}$ does exist for computational and mathemathical coherency, it is locked to $0$ during the fitting procedure and is functionally ignored.\n",
    "\n",
    "Concretely, the latent phenotype of any variant, $v$, from the experimental condition, $d$,\n",
    "is computed like so:\n",
    "\n",
    "$$\n",
    "\\phi_d(v) = \\beta_0 + \\beta^{(d)}_0 + \\sum_{m \\in v} (\\beta_{m} + \\Delta_{d, m})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\beta_0$ is a bias parameter applied to the latent prediction of all experiments.\n",
    "* $\\beta^d_0$ is a set of bias parameters, optionally applied to the latent phenotype of all _non-reference_ experiments.\n",
    "* $\\beta_{m}$ is the latent phenotypic effect of mutation $m$ shared by all experiments (See the note below), \n",
    "* $\\Delta_{d, m}$ is the shift of the effect of mutation $m$ in condition $d$.\n",
    "* $v$ is the set of all mutations relative to the reference wild type sequence including all potential non-identical wildtype mutations that separate condition $d$ from the reference condition.\n",
    "\n",
    "Importantly, If a _non-reference_ experiment has a different wildtype sequence from the _reference_ (e.g., the wildtype sequences are homologs), then the `multidms.MultiDmsData` object will encode non-reference genotypes relative to the reference wild type. \n",
    "Thus, the summation term includes all mutations at non-identical sites that convert between the two sequences.\n",
    "Likewise, If a mutation occurs at a non-identical site, then the mutation is encoded relative to the reference.\n",
    "For example, consider a protein where site $30$ is a Y in the non-reference experiment's wildtype sequence and an A in the reference experiment's wildtype sequence.\n",
    "If a variant from the non-reference experiment had a Y30G mutation, then the mutation would be defined as A30G in the summation term.\n",
    "This does not assume that Y30G has the same effect as A30G.\n",
    "It merely follows the strategy to define all sequences relative to the reference, which is practical because it ensures that each experiment informs the exact same set of $\\beta_m$ and $\\Delta_{d,m}$ parameters.\n",
    "If a variant from a non-reference experiment had a reversion mutation at a non-identical site (e.g., Y30A), then the mutation would not be included in the summation term for that variant since the variant would have the reference amino-acid identity at that site.\n",
    "In comparison, A30Y would be included in the summation term of all variants from the non-reference experiment that lack a mutation at site 30.\n",
    "If mutations at non-identical sites are not sampled in the DMS libraries (e.g., Y30A is missing from the non-reference experiment and A30Y is missing from the reference experiment), then $C_d$ can be used to capture the combined effects of these missing mutations.\n",
    "Otherwise, if all such mutations are sampled, $C_d$ can be locked at zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6416322",
   "metadata": {},
   "source": [
    "## global epistasis\n",
    "\n",
    "Latent phenotypes as described above give rise to functional scores according to a global-epistasis function.\n",
    "If this function is non-linear, then the model allows mutations to non-additively effect functional scores, helping to account for global epistasis. This type of model is useful for inferring effects of individual mutations in variants with more than one mutation. Below, we decribe the available options to model global-epistasis in the `multidms` infrastructure.\n",
    "\n",
    "**Note**: when analyzing DMS libraries in which variants have a maximum of one mutation, then it will not be possible for the model to learn the shape of global-epistasis, in which case we provide an `identity` global-epistasis function described below, which assumes no global epistasis, but still allows the user to take advantage of the rest of the `multidms` approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8613ea",
   "metadata": {},
   "source": [
    "### Sigmoidal model (default):\n",
    "\n",
    "By default, the global-epistasis function here assumes a sigmoidal relationship between\n",
    "a protein's latent property and its functional score measured in the experiment\n",
    "(e.g., log enrichment score). Using free parameters, the sigmoid\n",
    "can flexibly conform to an optimal shape informed by the data. \n",
    "Note that this function is independent from the\n",
    "experimental condition from which a variant is observed.\n",
    "\n",
    "Given _latent phenotype_, $\\phi_d(v) = z$, let\n",
    "\n",
    "$$\n",
    "g(z) =  \\frac{\\alpha_{scale}}{1 + e^{-z}} + \\alpha_{bias}\n",
    "$$\n",
    "\n",
    "Where $\\alpha_{scale}$ and $\\alpha_{bias}$ are free parameters defining the range and lower bound of the sigmoid, respectively.\n",
    "\n",
    "Below is an interactive plot showing the effect of the sigmoidal global epistasis as a function of an adjustable $\\alpha_{scale}$, and $\\alpha_{bias}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d3e310c",
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-0cef622b4e0d4bcba94e9228cf30ae3f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0cef622b4e0d4bcba94e9228cf30ae3f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0cef622b4e0d4bcba94e9228cf30ae3f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-5df0d8288b8899ccb5d4c64cc03b51be\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"latent phenotype\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"alpha_scale\", \"bind\": {\"input\": \"range\", \"max\": 10, \"min\": 0.1}, \"value\": 5}, {\"name\": \"alpha_bias\", \"bind\": {\"input\": \"range\", \"max\": 5, \"min\": -10}, \"value\": 0}], \"transform\": [{\"calculate\": \"(((1 / (1 + exp((-1 * datum['latent'])))) * alpha_scale) + alpha_bias)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-5df0d8288b8899ccb5d4c64cc03b51be\": [{\"latent\": -10.0}, {\"latent\": -9.797979797979798}, {\"latent\": -9.595959595959595}, {\"latent\": -9.393939393939394}, {\"latent\": -9.191919191919192}, {\"latent\": -8.98989898989899}, {\"latent\": -8.787878787878787}, {\"latent\": -8.585858585858587}, {\"latent\": -8.383838383838384}, {\"latent\": -8.181818181818182}, {\"latent\": -7.979797979797979}, {\"latent\": -7.777777777777778}, {\"latent\": -7.575757575757576}, {\"latent\": -7.373737373737374}, {\"latent\": -7.171717171717171}, {\"latent\": -6.96969696969697}, {\"latent\": -6.767676767676768}, {\"latent\": -6.565656565656566}, {\"latent\": -6.363636363636363}, {\"latent\": -6.161616161616162}, {\"latent\": -5.959595959595959}, {\"latent\": -5.757575757575758}, {\"latent\": -5.555555555555555}, {\"latent\": -5.353535353535354}, {\"latent\": -5.151515151515151}, {\"latent\": -4.94949494949495}, {\"latent\": -4.747474747474747}, {\"latent\": -4.545454545454546}, {\"latent\": -4.343434343434343}, {\"latent\": -4.141414141414142}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.737373737373738}, {\"latent\": -3.5353535353535355}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1313131313131315}, {\"latent\": -2.929292929292929}, {\"latent\": -2.7272727272727275}, {\"latent\": -2.525252525252525}, {\"latent\": -2.3232323232323235}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9191919191919187}, {\"latent\": -1.717171717171718}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3131313131313131}, {\"latent\": -1.1111111111111107}, {\"latent\": -0.9090909090909101}, {\"latent\": -0.7070707070707076}, {\"latent\": -0.5050505050505052}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.10101010101010033}, {\"latent\": 0.10101010101010033}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.5050505050505052}, {\"latent\": 0.7070707070707076}, {\"latent\": 0.9090909090909083}, {\"latent\": 1.1111111111111107}, {\"latent\": 1.3131313131313131}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.7171717171717162}, {\"latent\": 1.9191919191919187}, {\"latent\": 2.121212121212121}, {\"latent\": 2.3232323232323235}, {\"latent\": 2.525252525252524}, {\"latent\": 2.7272727272727266}, {\"latent\": 2.929292929292929}, {\"latent\": 3.1313131313131315}, {\"latent\": 3.333333333333334}, {\"latent\": 3.5353535353535346}, {\"latent\": 3.737373737373737}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.141414141414142}, {\"latent\": 4.3434343434343425}, {\"latent\": 4.545454545454545}, {\"latent\": 4.747474747474747}, {\"latent\": 4.94949494949495}, {\"latent\": 5.1515151515151505}, {\"latent\": 5.353535353535353}, {\"latent\": 5.555555555555555}, {\"latent\": 5.757575757575758}, {\"latent\": 5.9595959595959584}, {\"latent\": 6.161616161616163}, {\"latent\": 6.363636363636363}, {\"latent\": 6.565656565656564}, {\"latent\": 6.767676767676768}, {\"latent\": 6.969696969696969}, {\"latent\": 7.171717171717173}, {\"latent\": 7.373737373737374}, {\"latent\": 7.575757575757574}, {\"latent\": 7.777777777777779}, {\"latent\": 7.979797979797979}, {\"latent\": 8.18181818181818}, {\"latent\": 8.383838383838384}, {\"latent\": 8.585858585858585}, {\"latent\": 8.787878787878789}, {\"latent\": 8.98989898989899}, {\"latent\": 9.19191919191919}, {\"latent\": 9.393939393939394}, {\"latent\": 9.595959595959595}, {\"latent\": 9.7979797979798}, {\"latent\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 10, 100)})\n",
    "\n",
    "slider_s = alt.binding_range(min=0.1, max=10)\n",
    "var_s = alt.param(bind=slider_s, value=5, name=\"alpha_scale\")\n",
    "\n",
    "slider_b = alt.binding_range(min=-10, max=5)\n",
    "var_b = alt.param(bind=slider_b, value=0, name=\"alpha_bias\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=(1 / (1 + alt.expr.exp(-1*alt.datum['latent'])))\n",
    "        * var_s\n",
    "        + var_b\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"latent phenotype\", scale=alt.Scale(domain=[-10, 10])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 10]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_s, var_b)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6885d",
   "metadata": {},
   "source": [
    "### Softplus model\n",
    "\n",
    "This function is a log-transformed version of a sigmoid function from above, with  $\\alpha_{scale}$ and $\\alpha_{bias}$ parameters serving similar roles.\n",
    "The shape of this function mimics the Hill equation from the above example if the y-axis is instead the log of the fraction of protein molecules that are folded.\n",
    "Such a function could be more appropriate for modeling functional scores in log space.\n",
    "\n",
    "Given _latent phenotype_, $\\phi_d(v) = z$, let\n",
    "\n",
    "$$\n",
    "g(z) =  -\\alpha_\\text{scale}\\log\\left(1+e^{-z}\\right) + \\alpha_\\text{bias}\n",
    "$$\n",
    "\n",
    "**Note** In the `multidms` API, This behavior is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function `multidms.biophysical.softplus_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127046f",
   "metadata": {},
   "source": [
    "### Single-layer neural network model:\n",
    "\n",
    "If you prefer a less constrained shape for global epistasis, we also offer the ability to learn the shape of global epistasis using a single-layer neural network, sometimes referred to as a [multi-layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron). This is similar to what was presented by [Zhou et. al. 2022](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9522415/)\n",
    "\n",
    "For this option, the user defines a number of units in the singular hidden layer of the model. For each hidden unit, we introduce three parameters (two weights and a bias) to be inferred. All weights are clipped at zero to maintain assumptions of monotonicity in the resulting epistasis function shape.  The network applies a sigmoid activation to each internal unit before a final transformation and addition of a constant gives us our predicted functional score. \n",
    "\n",
    "Given _latent phenotype_, $\\phi_d(v) = z$, let\n",
    "\n",
    "$$\n",
    "g(z) = b^{o}+ \\sum_{i}^{n}(\\frac{w^{o}_{i}}{1 + e^{w^{l}_{i}*z + b^{l}_{i}}})\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $n$ is the number of units in the hidden layer.\n",
    "* $w^{l}_{i}$ and $w^{o}_{i}$ are free parameters representing latent and output tranformations, respectively, associated with unit $i$ in the hidden layer of the network. \n",
    "* $b^{l}_{i}$ is a free parameter, as an added bias term to unit $i$.\n",
    "* $b^{o}$ is a constant, singular free parameter.\n",
    "\n",
    "**Note** This is an advanced feature and we advise against it's use unless the other options are not sufficiently parameterized for particularly complex experimental conditions.\n",
    "\n",
    "**Note** In the `multidms` API, This behavior is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function `multidms.biophysical.single_layer_nn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cab98f",
   "metadata": {},
   "source": [
    "### Identity (no epistasis):\n",
    "\n",
    "Given _latent phenotype_, $\\phi_d(v) = z$, let\n",
    "\n",
    "$$\n",
    "g(z) = z\n",
    "$$\n",
    "\n",
    "In this functional form, there is no global epistasis: latent phenotypes are identical to functional scores.\n",
    "We recommend this functional form if none of the variants in the DMS experiment have more than one mutation, since multi-mutant variants are needed for the model to accurately infer a non-linear global-epistasis function.\n",
    "It can also be used as a baseline to determine if a non-linear global-epistasis function leads to better model fit.\n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function definition `multidms.biophysical.identity_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99477fac",
   "metadata": {},
   "source": [
    "## Optional normalization of observed functional scores\n",
    "\n",
    "A common way to compute functional scores is with log enrichment ratios, where all scores from a given condition are normalized so that the wildtype sequence from that condition has a value of zero.\n",
    "If wildtype sequences differ between conditions, then log enrichment ratios may not be directly comparable between conditions, as they are normalized to different reference points.\n",
    "This breaks the assumption of our joint-modeling scheme: that all functional scores are directly comparable.\n",
    "\n",
    "Ideally one or more of the same sequences would be included in the DMS library of each condition, so that all scores could be normalized to the same sequence.\n",
    "However, if there are no common sequences, then it may be possible to computationally estimate how to normalize scores so that they are more directly comparable.\n",
    "\n",
    "To this end, the model includes an additional parameter $\\gamma_d$ for each non-reference condition that allows functional scores from that condition to be normalized as follows:\n",
    "\n",
    "$$\n",
    "y_{v,d}^{\\text{norm}} = y_{v,d} + \\gamma_d\n",
    "$$\n",
    "\n",
    "where $\\gamma_d$ for the reference condition is locked at zero.\n",
    "There is a theoretical basis for adding $\\gamma_d$ to $y_{v,d}$ if functional scores are log enrichment ratios.\n",
    "As mentioned above, log enrichment ratios are normalized so that the wildtype sequence from a given experiment has a value of zero, according to the formula:\n",
    "\n",
    "$$\n",
    "y_{v,d} = \\log(E_{v,d}) - \\log(E_{\\text{wt},d})\n",
    "$$\n",
    "\n",
    "Thus, adding $\\gamma_d$ to $y_{v,d}$ is akin to renormalizing the log enrichment ratios so that a different sequence has a functional score of zero.\n",
    "In theory, for each non-reference condition, there is a $\\gamma_d$ that normalizes functional scores to be relative to the wildtype sequence of the reference condition.\n",
    "If these values are not experimentally measured, the model allows $\\gamma_d$ parameters to be fit during optimization, which assumes that the correct $\\gamma_d$ values will give the best model fit.\n",
    "Alternatively, $\\gamma_d$ values can be locked at zero if the user does not wish to implement this optional feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8e0a9",
   "metadata": {},
   "source": [
    "## Optional truncation of predicted functional scores\n",
    "\n",
    "By default, the output of the model is equal to the output of the global epistasis model chosen $\\hat{y}_d(v) = g(\\phi_d(v))$. However, we provide infrastructure to clip the predicted functional scores at some lower bound for users who may clip their input data. Here, we'll describe the motivation and approach for this.\n",
    "\n",
    "The commonly reported fold-change metric for functional scores described above falls victim to \n",
    "a limit of detection problem for deleterious mutations: once a mutation is sufficiently deleterious, further differences (eg, between -3 and -5) become largely meaningless because it is already basically nonfunctional.\n",
    "Thus, it's common for researchers to simply _truncate_ (i.e. _clip_) the functional at some lower bound $l$, where observations below are assumed largely to be outlier.\n",
    "\n",
    "When fitting the model to these data, it may be desirable to truncate \\emph{predicted} functional scores in a similar way.\n",
    "This is especially relevant when allowing $\\gamma_d$ values to be non-zero.\n",
    "For instance, say the user has truncated observed functional scores at a lower bound of $-3$ across all conditions.\n",
    "If $\\gamma_d$ is fit to $-1.0$ for one of the non-reference conditions, then the new floor of normalized functional scores for that condition would be $-4$, while the floor for the reference condition would still be $-3$.\n",
    "In this case, the global-epistasis function could find itself in a pickle: if it allowed predictions to go below $-3$, it could help model the floor of points in the non-reference condition, but hurt with modeling the floor of points in the reference condition.\n",
    "However, if it was able to truncate predicted scores for a given condition at the floor for that condition, then this tension would be relieved: predicted scores for the reference condition could be truncated at $-3$, while (non-truncated) predicted scores for the non-reference condition could go as low as $-4$.\n",
    "\n",
    "To this end, the software package provides an option to truncate predicted functional scores which should be used if (and only if) the user has clipped the functional scores in their data to some lower bound.\n",
    "To enable this, the mathematical model passes predicted functional scores through an activation function, $t$.\n",
    "\n",
    "In essence, this is a modified _softplus_ activation, ($\\text{softplus}(x)=\\log(1 + e^{x})$) with a _lower bound_ at $l + \\gamma_{h}$, as well as a _ramping_ coefficient, $\\lambda_{\\text{sp}}$. \n",
    "\n",
    "Concretely, if we let $z' = g(\\phi_d(v))$, then the predicted functional score of our model is given by:\n",
    "\n",
    "$$\n",
    "t(z') = \\lambda_{sp}\\log(1 + e^{\\frac{z' - l}{\\lambda_{sp}}}) + l\n",
    "$$\n",
    "\n",
    "Functionally speaking, this truncates scores below a lower bound, while leaving scores above (mostly) unaltered. There is a small range of input values where the function smoothly transitions between a flat regime (where data is truncated) and a linear regime (where data is not truncated). \n",
    "\n",
    "Below is an interactive plot showing the effect of the modified softplus activation as a function of an adjustable $\\lambda_{sp}$ scaling parameter, and lower bound, $l$:\n",
    "\n",
    "**Note** We recommend leaving the $\\lambda_{sp}$ parameter at it's default value of $0.1$. this ensures a sharp transition between regimes similar to a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) function, but retain the differentible property for gradient based optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02d0f67",
   "metadata": {
    "hideCode": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-7bbb579f9a004c1f88b5eadaad64c0e1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7bbb579f9a004c1f88b5eadaad64c0e1\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7bbb579f9a004c1f88b5eadaad64c0e1\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-cabdca2257cf20e376d04c62a66e94ee\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 5]}, \"title\": \"global epistasis prediction (z')\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 5]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"lambda_sp\", \"bind\": {\"input\": \"range\", \"max\": 2, \"min\": 0.1}, \"value\": 1}, {\"name\": \"lower_bound\", \"bind\": {\"input\": \"range\", \"max\": 0, \"min\": -10}, \"value\": -3.5}], \"transform\": [{\"calculate\": \"((log((1 + exp(((datum['latent'] - lower_bound) / lambda_sp)))) * lambda_sp) + lower_bound)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-cabdca2257cf20e376d04c62a66e94ee\": [{\"latent\": -10.0}, {\"latent\": -9.848484848484848}, {\"latent\": -9.696969696969697}, {\"latent\": -9.545454545454545}, {\"latent\": -9.393939393939394}, {\"latent\": -9.242424242424242}, {\"latent\": -9.09090909090909}, {\"latent\": -8.93939393939394}, {\"latent\": -8.787878787878787}, {\"latent\": -8.636363636363637}, {\"latent\": -8.484848484848484}, {\"latent\": -8.333333333333334}, {\"latent\": -8.181818181818182}, {\"latent\": -8.030303030303031}, {\"latent\": -7.878787878787879}, {\"latent\": -7.727272727272727}, {\"latent\": -7.575757575757576}, {\"latent\": -7.424242424242424}, {\"latent\": -7.2727272727272725}, {\"latent\": -7.121212121212121}, {\"latent\": -6.96969696969697}, {\"latent\": -6.818181818181818}, {\"latent\": -6.666666666666666}, {\"latent\": -6.515151515151516}, {\"latent\": -6.363636363636363}, {\"latent\": -6.212121212121212}, {\"latent\": -6.0606060606060606}, {\"latent\": -5.909090909090909}, {\"latent\": -5.757575757575758}, {\"latent\": -5.6060606060606055}, {\"latent\": -5.454545454545454}, {\"latent\": -5.303030303030303}, {\"latent\": -5.151515151515151}, {\"latent\": -5.0}, {\"latent\": -4.848484848484849}, {\"latent\": -4.696969696969697}, {\"latent\": -4.545454545454545}, {\"latent\": -4.393939393939394}, {\"latent\": -4.242424242424242}, {\"latent\": -4.090909090909091}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.787878787878788}, {\"latent\": -3.636363636363636}, {\"latent\": -3.4848484848484844}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1818181818181817}, {\"latent\": -3.0303030303030303}, {\"latent\": -2.878787878787879}, {\"latent\": -2.7272727272727266}, {\"latent\": -2.5757575757575752}, {\"latent\": -2.424242424242424}, {\"latent\": -2.2727272727272725}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9696969696969688}, {\"latent\": -1.8181818181818183}, {\"latent\": -1.666666666666666}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3636363636363633}, {\"latent\": -1.212121212121211}, {\"latent\": -1.0606060606060606}, {\"latent\": -0.9090909090909083}, {\"latent\": -0.7575757575757578}, {\"latent\": -0.6060606060606055}, {\"latent\": -0.45454545454545503}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.1515151515151505}, {\"latent\": 0.0}, {\"latent\": 0.15151515151515227}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.45454545454545503}, {\"latent\": 0.6060606060606055}, {\"latent\": 0.7575757575757578}, {\"latent\": 0.9090909090909101}, {\"latent\": 1.0606060606060606}, {\"latent\": 1.2121212121212128}, {\"latent\": 1.3636363636363633}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.6666666666666679}, {\"latent\": 1.8181818181818183}, {\"latent\": 1.9696969696969706}, {\"latent\": 2.121212121212121}, {\"latent\": 2.2727272727272734}, {\"latent\": 2.424242424242424}, {\"latent\": 2.575757575757576}, {\"latent\": 2.7272727272727284}, {\"latent\": 2.878787878787879}, {\"latent\": 3.030303030303031}, {\"latent\": 3.1818181818181817}, {\"latent\": 3.333333333333334}, {\"latent\": 3.4848484848484844}, {\"latent\": 3.6363636363636367}, {\"latent\": 3.787878787878789}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.090909090909092}, {\"latent\": 4.242424242424242}, {\"latent\": 4.3939393939393945}, {\"latent\": 4.545454545454547}, {\"latent\": 4.696969696969697}, {\"latent\": 4.8484848484848495}, {\"latent\": 5.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 5, 100)})\n",
    "\n",
    "slider_lsp = alt.binding_range(min=0.1, max=2)\n",
    "var_lambda_sp = alt.param(bind=slider_lsp, value=1, name=\"lambda_sp\")\n",
    "\n",
    "slider_lb = alt.binding_range(min=-10, max=0)\n",
    "var_lower_bound = alt.param(bind=slider_lb, value=-3.5, name=\"lower_bound\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=alt.expr.log(1 + alt.expr.exp((alt.datum['latent']-var_lower_bound)/var_lambda_sp))\n",
    "        * var_lambda_sp\n",
    "        + var_lower_bound\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"global epistasis prediction (z')\", scale=alt.Scale(domain=[-10, 5])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 5]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_lambda_sp, var_lower_bound)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc52e5",
   "metadata": {},
   "source": [
    "## Fitting procedure\n",
    "\n",
    "The `multidms` software package has a framework for fitting free parameters in the model given input DMS data.\n",
    "The mathematical model is coded in [Python](https://www.python.org/) using the [JAX](https://github.com/google/jax) , allowing for autograd and XLA compilation for high-performance optimization.\n",
    "Non-smooth optimization problem via proximal gradient descent in order to satisfy several simultaneous constrains such as L1 regularization, optionally locking parameters, and clipping parameters at pre-specified lower bounds.\n",
    "Specifically, we use [JAXopt](https://jaxopt.github.io/stable/index.html) to optimize parameters via full-batch proximal gradient descent using the [JAXopt.ProximalGradient](https://jaxopt.github.io/stable/_autosummary/jaxopt.ProximalGradient.html) function.\n",
    "\n",
    "To get ready for future more general non-smooth penalties, we use a proximal gradient method for the constrain. The objective splits into a smooth piece with a gradient, and a non-smooth piece with a proximity operator:\n",
    "\n",
    "The full objective function we use to optimize parameters involves summing two terms for each experiment $d$:\n",
    "\n",
    "$$\n",
    "L_{\\text{total}} = \\sum_{d} [L_{\\text{fit},d} + L_{\\text{reg},d}]\n",
    "$$\n",
    "\n",
    "The first term, $L_{\\text{fit},d}$, computes the loss between observed and predicted functional scores for a given condition, after applying the two optional modifications described above for renormalizing observed scores with $\\gamma_d$ and truncating predicted scores with $t$:\n",
    "\n",
    "$$\n",
    "    L_{\\text{fit},d} = \\frac{\\sum_{v} L_{h_{\\delta}}[(y_{v,d}+\\gamma_d) - t(\\hat{y}_{v,d})]}{n_d}\n",
    "$$\n",
    "\n",
    "where $L_{h_{\\delta}}$ is a Huber loss function with $\\delta=1$ by default, and $n_d$ is the number of variants in the condition.\n",
    "Dividing the numerator by $n_d$ makes it so that $L_{\\text{fit},d}$ returns the average loss across all variants.\n",
    "This ensures that each condition contributes equally to $L_\\text{total}$, regardless of the number of variants in that condition.\n",
    "The second term, $L_{\\text{reg},d}$, uses L1 regularization to penalize non-zero $\\Delta_{d,m}$ values:\n",
    "\n",
    "$$\n",
    "L_{\\text{reg},d} = \\lambda \\sum_{m} |\\Delta_{d,m}|\n",
    "$$\n",
    "\n",
    "where $\\lambda$ controls the strength of regularization.\n",
    "\n",
    "The goal of the regularization term is to drive $\\Delta_{d,m}$ parameters to zero unless they are strongly supported by the data.\n",
    "In the absence of regularization, $\\Delta_{d,m}$ parameters will be fit to optimize $L_{\\text{fit},d}$.\n",
    "Whether something is included depends on the data set size and the effect size, but you only highlight the former here.\n",
    "In the presence of regularization, the sensitivity of $\\Delta_{d,m}$ parameters to regularization will depend on both the magnitude of the shift and how many variants have the mutation $m$ in each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db441e59-8f59-4cac-a322-8adedad522b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
