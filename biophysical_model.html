
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Biophysical model &#8212; multidms 0.1.9 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/nbsphinx-code-cells.css" />
    <script src="_static/jquery.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="multidms fitting pipeline" href="fit_delta_BA1_example.html" />
    <link rel="prev" title="Installation" href="installation.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython.core.display</span> <span class="k">as</span> <span class="nn">di</span> <span class="c1"># Example: di.display_html(&#39;&lt;h3&gt;%s:&lt;/h3&gt;&#39; % str, raw=True)</span>
<span class="n">di</span><span class="o">.</span><span class="n">display_html</span><span class="p">(</span><span class="s1">&#39;&lt;script&gt;jQuery(function() {if (jQuery(&quot;body.notebook_app&quot;).length == 0) { jQuery(&quot;.input_area&quot;).toggle(); jQuery(&quot;.prompt&quot;).toggle();}});&lt;/script&gt;&#39;</span><span class="p">,</span> <span class="n">raw</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<script>jQuery(function() {if (jQuery("body.notebook_app").length == 0) { jQuery(".input_area").toggle(); jQuery(".prompt").toggle();}});</script></div>
</div>
<section id="Biophysical-model">
<h1>Biophysical model<a class="headerlink" href="#Biophysical-model" title="Permalink to this heading"></a></h1>
<p>The goal of <code class="docutils literal notranslate"><span class="pre">multidms</span></code> is to jointly infer mutational effects across multiple deep mutational scanning (DMS) experiments, including how much each mutation’s effect differs between experiments. We refer to these differences as <em>shifts</em>. If the experiments were performed with different homologs of the same protein, a shift would indicate epistasis between the shifted mutation and the amino-acid mutations that separate the homologs. Or, if they were performed with the same wildtype protein under
different selective conditions (e.g., selection for viral entry using different but related host receptors), shifts would indicate condition-specific effects. Ultimately, this model was designed to identify those shifts relative to user’s chosen <em>reference condition</em> with feature selection via a lasso (<span class="math notranslate nohighlight">\(L_1\)</span>) regularization <a class="footnote-reference brackets" href="#footcite-hastie2015lasso" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> of the shift parameters described in the additive <em>latent phenotype</em> section below.</p>
<p><code class="docutils literal notranslate"><span class="pre">multidms</span></code> is compatible with DMS data that have the following characteristics. First, the data must report a functional score (e.g., log enrichment ratio) for each variant from each DMS experiment, where a variant constitutes a unique gene sequence covering the entire mutagenized region. Thus, the deep-sequencing data must resolve complete haplotypes. Second, most mutations must be seen in multiple unique variants per experiment, as this number is the basis by which shifts are regularized
(see below). This second requirement is often met in DMS libraries with multiple mutations per variant, as long as each mutation occurs in multiple genetic backgrounds, or in libraries with one mutation per variant, as long as each variant is uniquely barcoded and individual mutations are found in the background of multiple barcodes. Given input data from one or more experiments, <code class="docutils literal notranslate"><span class="pre">multidms</span></code> fits to all the data and provides: (1) mutational effects <span class="math notranslate nohighlight">\(\beta\)</span> across all experiments, (2)
<span class="math notranslate nohighlight">\(\Delta\)</span>, how effects are shifted between experiments, and (3) a model to predict the functional score of any given variant.</p>
<p><strong>Note</strong>: We suggest reading the <a class="reference external" href="https://www.pnas.org/doi/10.1073/pnas.1804015115">Otwinowski et al. 2018</a> <a class="footnote-reference brackets" href="#footcite-otwinowski2018globalepistasis" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> paper to understand the approach for modeling global epistasis before reading the rest of the documentation.</p>
<section id="Joint-model-composition">
<h2>Joint model composition<a class="headerlink" href="#Joint-model-composition" title="Permalink to this heading"></a></h2>
<p>At a high level, the model is a composition of three functions which describe the expected biophysical interactions underlying a given phenotype; (1) <span class="math notranslate nohighlight">\(\phi\)</span>, an additive model describing a variant’s latent phenotype under a given condition, (2) <span class="math notranslate nohighlight">\(g\)</span>, a global epistasis model shared by all conditions to disentangle the effects of multiple mutations on the same variant, and (3) <span class="math notranslate nohighlight">\(t\)</span>, an <em>optional</em> final output activation function which can account for variant functional scores
which have been clipped at some lower bound <em>prior</em> to using <code class="docutils literal notranslate"><span class="pre">multidms</span></code>.</p>
<p>Concretely, the predicted phenotype for a given variant <span class="math notranslate nohighlight">\(v\)</span> under condition <span class="math notranslate nohighlight">\(d\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\hat{y}_{v, d} = t_{\gamma_{d}}(g_{\theta}(\phi_{d, \beta, \Delta}(v))\]</div>
<p>Where <span class="math notranslate nohighlight">\(\gamma\)</span>, <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(\beta\)</span>, and <span class="math notranslate nohighlight">\(\Delta\)</span> are <em>free</em> parameters inferred from experimental observations during the fitting process. We describe the individual components and their associated parameters in more detail below.</p>
<p>The motivation behind defining an abstract model in terms of its components are (1) modularity for method testing and development, and (2) the ability to provide multiple options for model components before jit-compilation and fitting of the specified model architecture. While there is only a single option for the latent prediction, <span class="math notranslate nohighlight">\(\phi\)</span>, we offer a few options <em>post-latent</em> modeling, <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(t\)</span>, that encompass the needs of differing research goals and experimental
techniques. Generally speaking, the package defaults for these components should be sufficient for most purposes, and in this case feel free to ignore the <code class="docutils literal notranslate"><span class="pre">multidms.biophysical</span></code> module all-together as this functionality is hidden unless explicitly specified during the instantiation of a <code class="docutils literal notranslate"><span class="pre">Model</span></code> object.</p>
<p>For more about how <code class="docutils literal notranslate"><span class="pre">multidms</span></code> model components are defined and composed, as well as how the models work with the <a class="reference external" href="https://github.com/google/jax">JAX</a> infrastructure to fit parameters, we suggest you take a look at the <a class="reference external" href="https://matsengrp.github.io/multidms/multidms.biophysical.html#biophysical-model">multidms package biophysical docs</a></p>
</section>
<section id="Latent-phenotype">
<h2>Latent phenotype<a class="headerlink" href="#Latent-phenotype" title="Permalink to this heading"></a></h2>
<p>For each mutation <span class="math notranslate nohighlight">\(m\)</span>, the model defines a single mutation effect parameter, <span class="math notranslate nohighlight">\(\beta_{m}\)</span> shared by all conditions. Additionally for each non-reference experiment <span class="math notranslate nohighlight">\(d\)</span> (the letter <span class="math notranslate nohighlight">\(d\)</span> is used as a mnemonic for DMS), the model defines the set of mutational shift parameters, <span class="math notranslate nohighlight">\(\Delta_{d,m}\)</span>, that quantifies the shift a given mutation’s effect relative to some reference condition. Each mutation, for each non-reference condition, is associated with an independent shift
parameter. For example, consider three total experimental conditions, <span class="math notranslate nohighlight">\(d \in \{1, 2, 3\}\)</span>, where <span class="math notranslate nohighlight">\(d = 1\)</span> is the <em>reference</em> condition. The model then defines two sets of (non-reference) <em>shift</em> parameters <span class="math notranslate nohighlight">\(\Delta_{2, m}\)</span>, <span class="math notranslate nohighlight">\(\Delta_{3, m}\)</span> that may be fit to non-zero values.</p>
<p>Concretely, the latent phenotype of any variant, <span class="math notranslate nohighlight">\(v\)</span>, from the experimental condition, <span class="math notranslate nohighlight">\(d\)</span>, is computed like so:</p>
<div class="math notranslate nohighlight">
\[\phi_d(v) = \beta_0 + \alpha_d + \sum_{m \in v} (\beta_{m} + \Delta_{d, m})\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> is a wildtype offset parameter applied to the latent prediction of all experiments.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha_d\)</span> is a set of bias parameters, optionally applied to the latent phenotype of all <em>non-reference</em> experiments. These parameters may capture the effect of the <em>bundle</em> of non-identical mutations which may exist between experiments.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_{m}\)</span> is the latent phenotypic effect of mutation <span class="math notranslate nohighlight">\(m\)</span> shared by all experiments (See the note below),</p></li>
<li><p><span class="math notranslate nohighlight">\(\Delta_{d, m}\)</span> is the shift of the effect of mutation <span class="math notranslate nohighlight">\(m\)</span> in condition <span class="math notranslate nohighlight">\(d\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(v\)</span> is the set of all mutations relative to the reference wild type sequence including all potential non-identical wildtype mutations that separate condition <span class="math notranslate nohighlight">\(d\)</span> from the reference condition.</p></li>
</ul>
<p>If a <em>non-reference</em> experiment has a different wildtype sequence from the <em>reference</em> (e.g., the wildtype sequences are homologs), then the <code class="docutils literal notranslate"><span class="pre">multidms.Data</span></code> object will encode non-reference genotypes relative to the reference wild type. Thus, the summation term includes all mutations at non-identical sites that convert between the two sequences. Likewise, If a mutation occurs at a non-identical site, then the mutation is encoded relative to the reference. For example, consider a protein where
site <span class="math notranslate nohighlight">\(30\)</span> is a Y in the non-reference experiment’s wildtype sequence and an A in the reference experiment’s wildtype sequence. If a variant from the non-reference experiment had a Y30G mutation, then the mutation would be defined as A30G in the summation term. This does not assume that Y30G has the same effect as A30G. It merely follows the strategy to define all sequences relative to the reference, which is practical because it ensures that each experiment informs the exact same set of
<span class="math notranslate nohighlight">\(\beta_m\)</span> and <span class="math notranslate nohighlight">\(\Delta_{d,m}\)</span> parameters. If a variant from a non-reference experiment had a reversion mutation at a non-identical site (e.g., Y30A), then the mutation would not be included in the summation term for that variant since the variant would have the reference amino-acid identity at that site. In comparison, A30Y would be included in the summation term of all variants from the non-reference experiment that lack a mutation at site 30. If mutations at non-identical sites are
not sampled in the DMS libraries (e.g., Y30A is missing from the non-reference experiment and A30Y is missing from the reference experiment), then <span class="math notranslate nohighlight">\(\alpha_d\)</span> can be used to capture the combined effects of these missing mutations. Otherwise, if all such mutations are sampled, <span class="math notranslate nohighlight">\(\alpha_d\)</span> can be locked at zero.</p>
<p>One aspect of this approach which may be important to note, is that none of the experiment wildtype predictions are guerenteed to be zero-centered due to the shift, and offset parameters. To correct for this, <code class="docutils literal notranslate"><span class="pre">multidms</span></code> offers the ability (in predictive functions) to report both functional scores, as well as the functional score <em>effect</em> values which are reported as the difference between any given variant functional score and the wildtype such that
<span class="math notranslate nohighlight">\(\hat{y}_{v, d} = \hat{y}_{v, d} - \hat{y}_{\text{WT}, d}\)</span>. The API documentation specifies how to achieve the desired behavior.</p>
</section>
<section id="Global-epistasis">
<h2>Global epistasis<a class="headerlink" href="#Global-epistasis" title="Permalink to this heading"></a></h2>
<p>Latent phenotypes as described above give rise to functional scores according to a global-epistasis function. If this function is non-linear, then the model allows mutations to non-additively effect functional scores, helping to account for global epistasis. This type of model is useful for inferring effects of individual mutations in variants with more than one mutation. Below, we decribe the available options to model global-epistasis in the <code class="docutils literal notranslate"><span class="pre">multidms</span></code> infrastructure.</p>
<p><strong>Note</strong>: when analyzing DMS libraries in which variants have a maximum of one mutation, then it will not be possible for the model to learn the shape of global-epistasis, in which case we provide an <code class="docutils literal notranslate"><span class="pre">identity</span></code> global-epistasis function described below, which assumes no global epistasis, but still allows the user to take advantage of the rest of the <code class="docutils literal notranslate"><span class="pre">multidms</span></code> approach.</p>
<section id="Sigmoidal-model-(default):">
<h3>Sigmoidal model (default):<a class="headerlink" href="#Sigmoidal-model-(default):" title="Permalink to this heading"></a></h3>
<p>By default, the global-epistasis function here assumes a sigmoidal relationship between a protein’s latent property and its functional score measured in the experiment (e.g., log enrichment score). Using free parameters, the sigmoid can flexibly conform to an optimal shape informed by the data. Note that this function is independent from the experimental condition from which a variant is observed.</p>
<p>Given latent phenotype, <span class="math notranslate nohighlight">\(\phi_d(v) = z\)</span>, let</p>
<div class="math notranslate nohighlight">
\[g(z) =  \frac{\theta_{\text{scale}}}{1 + e^{-z}} + \theta_{\text{bias}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\theta_{\text{scale}}\)</span> and <span class="math notranslate nohighlight">\(\theta_{\text{bias}}\)</span> are free parameters defining the range and lower bound of the sigmoid, respectively.</p>
<p>Below is an interactive plot showing the effect of the sigmoidal global epistasis as a function of an adjustable <span class="math notranslate nohighlight">\(\theta_{\text{scale}}\)</span>, and <span class="math notranslate nohighlight">\(\theta_{\text{bias}}\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;latent&quot;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)})</span>

<span class="n">slider_s</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">var_s</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_s</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;theta_scale&quot;</span><span class="p">)</span>

<span class="n">slider_b</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">var_b</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_b</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;theta_bias&quot;</span><span class="p">)</span>

<span class="p">(</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="o">.</span><span class="n">transform_calculate</span><span class="p">(</span>
        <span class="n">phenotype</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alt</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">alt</span><span class="o">.</span><span class="n">datum</span><span class="p">[</span><span class="s1">&#39;latent&#39;</span><span class="p">])))</span>
        <span class="o">*</span> <span class="n">var_s</span>
        <span class="o">+</span> <span class="n">var_b</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;latent phenotype&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
        <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">&quot;phenotype:Q&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;predicted phenotype&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">mark_line</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add_params</span><span class="p">(</span><span class="n">var_s</span><span class="p">,</span> <span class="n">var_b</span><span class="p">)</span>
<span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div id="altair-viz-751fe3f1ca74427391e995ac96a6ec5b"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-751fe3f1ca74427391e995ac96a6ec5b") {
      outputDiv = document.getElementById("altair-viz-751fe3f1ca74427391e995ac96a6ec5b");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.6.1"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "data": {"name": "data-ebf3a22bc86bf79e10d2059712505f43"}, "mark": {"type": "line"}, "encoding": {"x": {"field": "latent", "scale": {"domain": [-5, 5]}, "title": "latent phenotype", "type": "quantitative"}, "y": {"field": "phenotype", "scale": {"domain": [-5, 5]}, "title": "predicted phenotype", "type": "quantitative"}}, "params": [{"name": "theta_scale", "bind": {"input": "range", "max": 10, "min": 0.1}, "value": 5}, {"name": "theta_bias", "bind": {"input": "range", "max": 5, "min": -10}, "value": 0}], "transform": [{"calculate": "(((1 / (1 + exp((-1 * datum['latent'])))) * theta_scale) + theta_bias)", "as": "phenotype"}], "$schema": "https://vega.github.io/schema/vega-lite/v5.6.1.json", "datasets": {"data-ebf3a22bc86bf79e10d2059712505f43": [{"latent": -5.0}, {"latent": -4.795918367346939}, {"latent": -4.591836734693878}, {"latent": -4.387755102040816}, {"latent": -4.183673469387755}, {"latent": -3.979591836734694}, {"latent": -3.7755102040816326}, {"latent": -3.571428571428571}, {"latent": -3.36734693877551}, {"latent": -3.163265306122449}, {"latent": -2.9591836734693877}, {"latent": -2.7551020408163263}, {"latent": -2.5510204081632653}, {"latent": -2.3469387755102042}, {"latent": -2.142857142857143}, {"latent": -1.9387755102040813}, {"latent": -1.7346938775510203}, {"latent": -1.5306122448979593}, {"latent": -1.3265306122448979}, {"latent": -1.1224489795918364}, {"latent": -0.9183673469387754}, {"latent": -0.7142857142857144}, {"latent": -0.5102040816326525}, {"latent": -0.3061224489795915}, {"latent": -0.1020408163265305}, {"latent": 0.1020408163265305}, {"latent": 0.3061224489795915}, {"latent": 0.5102040816326534}, {"latent": 0.7142857142857144}, {"latent": 0.9183673469387754}, {"latent": 1.1224489795918373}, {"latent": 1.3265306122448983}, {"latent": 1.5306122448979593}, {"latent": 1.7346938775510203}, {"latent": 1.9387755102040813}, {"latent": 2.1428571428571432}, {"latent": 2.3469387755102042}, {"latent": 2.5510204081632653}, {"latent": 2.755102040816327}, {"latent": 2.959183673469388}, {"latent": 3.163265306122449}, {"latent": 3.36734693877551}, {"latent": 3.571428571428571}, {"latent": 3.775510204081632}, {"latent": 3.979591836734695}, {"latent": 4.183673469387756}, {"latent": 4.387755102040817}, {"latent": 4.591836734693878}, {"latent": 4.795918367346939}, {"latent": 5.0}]}}, {"mode": "vega-lite"});
</script></div>
</div>
</section>
<section id="Softplus-model">
<h3>Softplus model<a class="headerlink" href="#Softplus-model" title="Permalink to this heading"></a></h3>
<p>This function is a log-transformed version of a sigmoid function from above, with <span class="math notranslate nohighlight">\(\theta_\text{scale}\)</span> and <span class="math notranslate nohighlight">\(\theta_\text{bias}\)</span> parameters serving similar roles. The shape of this function mimics the Hill equation from the above example if the y-axis is instead the log of the fraction of protein molecules that are folded. Such a function could be more appropriate for modeling functional scores in log space. You may note that this function has no natural lower bound, and thus it is
recommended to use this model with a user defined lower bound which is described in the <em>Optional truncation of predicted functional scores</em> section below.</p>
<p>Given latent phenotype, <span class="math notranslate nohighlight">\(\phi_d(v) = z\)</span>, let</p>
<div class="math notranslate nohighlight">
\[g(z) =  -\theta_\text{scale}\log\left(1+e^{-z}\right) + \theta_\text{bias}\]</div>
<p><strong>Note</strong> In the <code class="docutils literal notranslate"><span class="pre">multidms</span></code> API, This behavior is accomplished by setting the <code class="docutils literal notranslate"><span class="pre">output_activation</span></code> parameter in the constructor for <code class="docutils literal notranslate"><span class="pre">Model</span></code> to be a pointer to the function <code class="docutils literal notranslate"><span class="pre">multidms.biophysical.softplus_activation</span></code></p>
<p>Below is an interactive plot showing the effect of the modified softplus function as a function of an adjustable <span class="math notranslate nohighlight">\(\theta_\text{scale}\)</span> scaling parameter, and lower bound, <span class="math notranslate nohighlight">\(\theta_\text{bias}\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;latent&quot;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)})</span>

<span class="n">slider_lsp</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">alpha_scale</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_lsp</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lambda_sp&quot;</span><span class="p">)</span>

<span class="n">slider_lb</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">alpha_bias</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_lb</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lower_bound&quot;</span><span class="p">)</span>

<span class="p">(</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="o">.</span><span class="n">transform_calculate</span><span class="p">(</span>
        <span class="n">phenotype</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alt</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">alt</span><span class="o">.</span><span class="n">datum</span><span class="p">[</span><span class="s1">&#39;latent&#39;</span><span class="p">]))</span>
        <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">alpha_scale</span><span class="p">)</span>
        <span class="o">+</span> <span class="n">alpha_bias</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;global epistasis prediction (z&#39;)&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
        <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">&quot;phenotype:Q&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;predicted phenotype&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">mark_line</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add_params</span><span class="p">(</span><span class="n">alpha_scale</span><span class="p">,</span> <span class="n">alpha_bias</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div id="altair-viz-ac092d0f062a4e1b931f8a04c69a2da6"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-ac092d0f062a4e1b931f8a04c69a2da6") {
      outputDiv = document.getElementById("altair-viz-ac092d0f062a4e1b931f8a04c69a2da6");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.6.1"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "data": {"name": "data-ebf3a22bc86bf79e10d2059712505f43"}, "mark": {"type": "line"}, "encoding": {"x": {"field": "latent", "scale": {"domain": [-5, 5]}, "title": "global epistasis prediction (z')", "type": "quantitative"}, "y": {"field": "phenotype", "scale": {"domain": [-5, 5]}, "title": "predicted phenotype", "type": "quantitative"}}, "params": [{"name": "lambda_sp", "bind": {"input": "range", "max": 5, "min": 1}, "value": 1}, {"name": "lower_bound", "bind": {"input": "range", "max": 5, "min": 0}, "value": 2}], "transform": [{"calculate": "((log((1 + exp((-1 * datum['latent'])))) * (-1 * lambda_sp)) + lower_bound)", "as": "phenotype"}], "$schema": "https://vega.github.io/schema/vega-lite/v5.6.1.json", "datasets": {"data-ebf3a22bc86bf79e10d2059712505f43": [{"latent": -5.0}, {"latent": -4.795918367346939}, {"latent": -4.591836734693878}, {"latent": -4.387755102040816}, {"latent": -4.183673469387755}, {"latent": -3.979591836734694}, {"latent": -3.7755102040816326}, {"latent": -3.571428571428571}, {"latent": -3.36734693877551}, {"latent": -3.163265306122449}, {"latent": -2.9591836734693877}, {"latent": -2.7551020408163263}, {"latent": -2.5510204081632653}, {"latent": -2.3469387755102042}, {"latent": -2.142857142857143}, {"latent": -1.9387755102040813}, {"latent": -1.7346938775510203}, {"latent": -1.5306122448979593}, {"latent": -1.3265306122448979}, {"latent": -1.1224489795918364}, {"latent": -0.9183673469387754}, {"latent": -0.7142857142857144}, {"latent": -0.5102040816326525}, {"latent": -0.3061224489795915}, {"latent": -0.1020408163265305}, {"latent": 0.1020408163265305}, {"latent": 0.3061224489795915}, {"latent": 0.5102040816326534}, {"latent": 0.7142857142857144}, {"latent": 0.9183673469387754}, {"latent": 1.1224489795918373}, {"latent": 1.3265306122448983}, {"latent": 1.5306122448979593}, {"latent": 1.7346938775510203}, {"latent": 1.9387755102040813}, {"latent": 2.1428571428571432}, {"latent": 2.3469387755102042}, {"latent": 2.5510204081632653}, {"latent": 2.755102040816327}, {"latent": 2.959183673469388}, {"latent": 3.163265306122449}, {"latent": 3.36734693877551}, {"latent": 3.571428571428571}, {"latent": 3.775510204081632}, {"latent": 3.979591836734695}, {"latent": 4.183673469387756}, {"latent": 4.387755102040817}, {"latent": 4.591836734693878}, {"latent": 4.795918367346939}, {"latent": 5.0}]}}, {"mode": "vega-lite"});
</script></div>
</div>
</section>
<section id="Single-layer-neural-network-model:">
<h3>Single-layer neural network model:<a class="headerlink" href="#Single-layer-neural-network-model:" title="Permalink to this heading"></a></h3>
<p>If you prefer a less constrained shape for global epistasis, we also offer the ability to learn the shape of global epistasis using a single-layer neural network, sometimes referred to as a <a class="reference external" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multi-layer perceptron</a>. This is similar to what was presented by <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9522415/">Zhou et. al. 2022</a></p>
<p>For this option, the user defines a number of units in the singular hidden layer of the model. For each hidden unit, we introduce three parameters (two weights and a bias) to be inferred. All weights are clipped at zero to maintain assumptions of monotonicity in the resulting epistasis function shape. The network applies a sigmoid activation to each internal unit before a final transformation and addition of a constant gives us our predicted functional score.</p>
<p>Given latent phenotype, <span class="math notranslate nohighlight">\(\phi_d(v) = z\)</span>, let</p>
<div class="math notranslate nohighlight">
\[g(z) = b^{o}+ \sum_{i}^{n} \frac{w^{o}_{i}}{1 + e^{w^{l}_{i}*z + b^{l}_{i}}}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> is the number of units in the hidden layer.</p></li>
<li><p><span class="math notranslate nohighlight">\(w^{l}_{i}\)</span> and <span class="math notranslate nohighlight">\(w^{o}_{i}\)</span> are free parameters representing latent and output tranformations, respectively, associated with unit <span class="math notranslate nohighlight">\(i\)</span> in the hidden layer of the network.</p></li>
<li><p><span class="math notranslate nohighlight">\(b^{l}_{i}\)</span> is a free parameter, as an added bias term to unit <span class="math notranslate nohighlight">\(i\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(b^{o}\)</span> is a constant, singular free parameter.</p></li>
</ul>
<p><strong>Note</strong> This is an advanced feature and we advise against its use unless the other options are not sufficiently parameterized for particularly complex experimental conditions.</p>
<p><strong>Note</strong> In the <code class="docutils literal notranslate"><span class="pre">multidms</span></code> API, This behavior is accomplished by setting the <code class="docutils literal notranslate"><span class="pre">output_activation</span></code> parameter in the constructor for <code class="docutils literal notranslate"><span class="pre">Model</span></code> to be a pointer to the function <code class="docutils literal notranslate"><span class="pre">multidms.biophysical.single_layer_nn</span></code>.</p>
</section>
<section id="Identity-(no-epistasis):">
<h3>Identity (no epistasis):<a class="headerlink" href="#Identity-(no-epistasis):" title="Permalink to this heading"></a></h3>
<p>Given latent phenotype, <span class="math notranslate nohighlight">\(\phi_d(v) = z\)</span>, let</p>
<div class="math notranslate nohighlight">
\[g(z) = z\]</div>
<p>In this functional form, there is no global epistasis: latent phenotypes are identical to functional scores. We recommend this functional form if none of the variants in the DMS experiment have more than one mutation, since multi-mutant variants are needed for the model to accurately infer a non-linear global-epistasis function. It can also be used as a baseline to determine if a non-linear global-epistasis function leads to better model fit.</p>
<p><strong>Note</strong> In the <code class="docutils literal notranslate"><span class="pre">multidms</span></code> API, This is accomplished by setting the <code class="docutils literal notranslate"><span class="pre">output_activation</span></code> parameter in the constructor for <code class="docutils literal notranslate"><span class="pre">Model</span></code> to be a pointer to the function definition <code class="docutils literal notranslate"><span class="pre">multidms.biophysical.identity_activation</span></code>.</p>
</section>
</section>
<section id="Optional-normalization-of-observed-functional-scores">
<h2>Optional normalization of observed functional scores<a class="headerlink" href="#Optional-normalization-of-observed-functional-scores" title="Permalink to this heading"></a></h2>
<p>A common way to compute functional scores is with log enrichment ratios, where all scores from a given condition are normalized so that the wildtype sequence from that condition has a value of zero. If wildtype sequences differ between conditions, then log enrichment ratios may not be directly comparable between conditions, as they are normalized to different reference points. This breaks the assumption of our joint-modeling scheme: that all functional scores are directly comparable.</p>
<p>Ideally one or more of the same sequences would be included in the DMS library of each condition, so that all scores could be normalized to the same sequence. However, if there are no common sequences, then it may be possible to computationally estimate how to normalize scores so that they are more directly comparable.</p>
<p>To this end, the model includes an additional parameter <span class="math notranslate nohighlight">\(\gamma_d\)</span> for each non-reference condition that allows functional scores from that condition to be normalized as follows:</p>
<div class="math notranslate nohighlight">
\[y_{v,d}^{\text{norm}} = y_{v,d} + \gamma_d\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma_d\)</span> for the reference condition is locked at zero. There is a theoretical basis for adding <span class="math notranslate nohighlight">\(\gamma_d\)</span> to <span class="math notranslate nohighlight">\(y_{v,d}\)</span> if functional scores are log enrichment ratios. As mentioned above, log enrichment ratios are normalized so that the wildtype sequence from a given experiment has a value of zero, according to the formula:</p>
<div class="math notranslate nohighlight">
\[y_{v,d} = \log(E_{v,d}) - \log(E_{\text{wt},d})\]</div>
<p>Thus, adding <span class="math notranslate nohighlight">\(\gamma_d\)</span> to <span class="math notranslate nohighlight">\(y_{v,d}\)</span> is akin to renormalizing the log enrichment ratios so that a different sequence has a functional score of zero. In theory, for each non-reference condition, there is a <span class="math notranslate nohighlight">\(\gamma_d\)</span> that normalizes functional scores to be relative to the wildtype sequence of the reference condition. If these values are not experimentally measured, the model allows <span class="math notranslate nohighlight">\(\gamma_d\)</span> parameters to be fit during optimization, which assumes that the correct
<span class="math notranslate nohighlight">\(\gamma_d\)</span> values will give the best model fit. Alternatively, <span class="math notranslate nohighlight">\(\gamma_d\)</span> values can be locked at zero if the user does not wish to implement this optional feature.</p>
</section>
<section id="Optional-truncation-of-predicted-functional-scores">
<h2>Optional truncation of predicted functional scores<a class="headerlink" href="#Optional-truncation-of-predicted-functional-scores" title="Permalink to this heading"></a></h2>
<p>By default, the output of the model is equal to the output of the global epistasis model chosen <span class="math notranslate nohighlight">\(\hat{y}_d(v) = g(\phi_d(v))\)</span>. However, we provide infrastructure to clip the predicted functional scores at some lower bound for users who may clip their input data. Here, we’ll describe the motivation and approach for this.</p>
<p>The commonly reported fold-change metric for functional scores described above falls victim to a limit of detection problem for deleterious mutations: once a mutation is sufficiently deleterious, further differences (eg, between -3 and -5) become largely meaningless because it is already basically nonfunctional. Thus, it’s common for researchers to simply <em>truncate</em> (i.e. <em>clip</em>) the functional at some lower bound <span class="math notranslate nohighlight">\(l\)</span>, where observations below are assumed largely to be outlier.</p>
<p>When fitting the model to these data, it may be desirable to truncate <em>predicted</em> functional scores in a similar way. This is especially relevant when allowing <span class="math notranslate nohighlight">\(\gamma_d\)</span> values to be non-zero. For instance, say the user has truncated observed functional scores at a lower bound of <span class="math notranslate nohighlight">\(-3\)</span> across all conditions. If <span class="math notranslate nohighlight">\(\gamma_d\)</span> is fit to <span class="math notranslate nohighlight">\(-1.0\)</span> for one of the non-reference conditions, then the new floor of normalized functional scores for that condition would be <span class="math notranslate nohighlight">\(-4\)</span>,
while the floor for the reference condition would still be <span class="math notranslate nohighlight">\(-3\)</span>. In this case, the global-epistasis function could find itself in a pickle: if it allowed predictions to go below <span class="math notranslate nohighlight">\(-3\)</span>, it could help model the floor of points in the non-reference condition, but hurt with modeling the floor of points in the reference condition. However, if it was able to truncate predicted scores for a given condition at the floor for that condition, then this tension would be relieved: predicted scores
for the reference condition could be truncated at <span class="math notranslate nohighlight">\(-3\)</span>, while (non-truncated) predicted scores for the non-reference condition could go as low as <span class="math notranslate nohighlight">\(-4\)</span>.</p>
<p>To this end, the software package provides an option to truncate predicted functional scores which should be used if (and only if) the user has clipped the functional scores in their data to some lower bound. To enable this, the mathematical model passes predicted functional scores through an activation function, <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>In essence, this is a modified <em>softplus</em> activation, (<span class="math notranslate nohighlight">\(\text{softplus}(x)=\log(1 + e^{x})\)</span>) with a <em>lower bound</em> at <span class="math notranslate nohighlight">\(l + \gamma_{h}\)</span>, as well as a <em>ramping</em> coefficient, <span class="math notranslate nohighlight">\(\lambda_{\text{sp}}\)</span>.</p>
<p>Concretely, if we let <span class="math notranslate nohighlight">\(z' = g(\phi_d(v))\)</span>, then the predicted functional score of our model is given by:</p>
<div class="math notranslate nohighlight">
\[t(z') = \lambda_{sp}\log(1 + e^{\frac{z' - l}{\lambda_{sp}}}) + l\]</div>
<p>Functionally speaking, this truncates scores below a lower bound, while leaving scores above (mostly) unaltered. There is a small range of input values where the function smoothly transitions between a flat regime (where data is truncated) and a linear regime (where data is not truncated).</p>
<p><strong>Note</strong> We recommend leaving the <span class="math notranslate nohighlight">\(\lambda_{sp}\)</span> parameter at It’s default value of <span class="math notranslate nohighlight">\(0.1\)</span>. this ensures a sharp transition between regimes similar to a <a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> function, but retain the differentiable property for gradient based optimization. However, the option is there in case you find the model will not converge.</p>
<p>Below is an interactive plot showing the effect of the modified softplus activation as a function of an adjustable <span class="math notranslate nohighlight">\(\lambda_{sp}\)</span> scaling parameter, and lower bound, <span class="math notranslate nohighlight">\(l\)</span>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Below is an interactive plot showing the effect of the modified</span>
<span class="c1"># softplus activation as a function of an adjustable $\lambda_{sp}$ scaling parameter, and lower bound, $l$:</span>

<span class="kn">import</span> <span class="nn">altair</span> <span class="k">as</span> <span class="nn">alt</span>

<span class="kn">import</span> <span class="nn">numpy</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;latent&quot;</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)})</span>

<span class="n">slider_lsp</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">var_lambda_sp</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_lsp</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lambda_sp&quot;</span><span class="p">)</span>

<span class="n">slider_lb</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">binding_range</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">var_lower_bound</span> <span class="o">=</span> <span class="n">alt</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">slider_lb</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mf">3.5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;lower_bound&quot;</span><span class="p">)</span>

<span class="p">(</span>
    <span class="n">alt</span><span class="o">.</span><span class="n">Chart</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="o">.</span><span class="n">transform_calculate</span><span class="p">(</span>
        <span class="n">phenotype</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">alt</span><span class="o">.</span><span class="n">expr</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="n">alt</span><span class="o">.</span><span class="n">datum</span><span class="p">[</span><span class="s1">&#39;latent&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">var_lower_bound</span><span class="p">)</span><span class="o">/</span><span class="n">var_lambda_sp</span><span class="p">))</span>
        <span class="o">*</span> <span class="n">var_lambda_sp</span>
        <span class="o">+</span> <span class="n">var_lower_bound</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">encode</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">X</span><span class="p">(</span><span class="s2">&quot;latent&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;global epistasis prediction (z&#39;)&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">])),</span>
        <span class="n">y</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Y</span><span class="p">(</span><span class="s2">&quot;phenotype:Q&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;predicted phenotype&quot;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">alt</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
    <span class="p">)</span>
    <span class="o">.</span><span class="n">mark_line</span><span class="p">()</span>
    <span class="o">.</span><span class="n">add_params</span><span class="p">(</span><span class="n">var_lambda_sp</span><span class="p">,</span> <span class="n">var_lower_bound</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div id="altair-viz-7a419dff89f64d09b5456acd6411811f"></div>
<script type="text/javascript">
  var VEGA_DEBUG = (typeof VEGA_DEBUG == "undefined") ? {} : VEGA_DEBUG;
  (function(spec, embedOpt){
    let outputDiv = document.currentScript.previousElementSibling;
    if (outputDiv.id !== "altair-viz-7a419dff89f64d09b5456acd6411811f") {
      outputDiv = document.getElementById("altair-viz-7a419dff89f64d09b5456acd6411811f");
    }
    const paths = {
      "vega": "https://cdn.jsdelivr.net/npm/vega@5?noext",
      "vega-lib": "https://cdn.jsdelivr.net/npm/vega-lib?noext",
      "vega-lite": "https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext",
      "vega-embed": "https://cdn.jsdelivr.net/npm/vega-embed@6?noext",
    };

    function maybeLoadScript(lib, version) {
      var key = `${lib.replace("-", "")}_version`;
      return (VEGA_DEBUG[key] == version) ?
        Promise.resolve(paths[lib]) :
        new Promise(function(resolve, reject) {
          var s = document.createElement('script');
          document.getElementsByTagName("head")[0].appendChild(s);
          s.async = true;
          s.onload = () => {
            VEGA_DEBUG[key] = version;
            return resolve(paths[lib]);
          };
          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);
          s.src = paths[lib];
        });
    }

    function showError(err) {
      outputDiv.innerHTML = `<div class="error" style="color:red;">${err}</div>`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === "function" && define.amd) {
      requirejs.config({paths});
      require(["vega-embed"], displayChart, err => showError(`Error loading script: ${err.message}`));
    } else {
      maybeLoadScript("vega", "5")
        .then(() => maybeLoadScript("vega-lite", "5.6.1"))
        .then(() => maybeLoadScript("vega-embed", "6"))
        .catch(showError)
        .then(() => displayChart(vegaEmbed));
    }
  })({"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "data": {"name": "data-cabdca2257cf20e376d04c62a66e94ee"}, "mark": {"type": "line"}, "encoding": {"x": {"field": "latent", "scale": {"domain": [-10, 5]}, "title": "global epistasis prediction (z')", "type": "quantitative"}, "y": {"field": "phenotype", "scale": {"domain": [-10, 5]}, "title": "predicted phenotype", "type": "quantitative"}}, "params": [{"name": "lambda_sp", "bind": {"input": "range", "max": 2, "min": 0.1}, "value": 1}, {"name": "lower_bound", "bind": {"input": "range", "max": 0, "min": -10}, "value": -3.5}], "transform": [{"calculate": "((log((1 + exp(((datum['latent'] - lower_bound) / lambda_sp)))) * lambda_sp) + lower_bound)", "as": "phenotype"}], "$schema": "https://vega.github.io/schema/vega-lite/v5.6.1.json", "datasets": {"data-cabdca2257cf20e376d04c62a66e94ee": [{"latent": -10.0}, {"latent": -9.848484848484848}, {"latent": -9.696969696969697}, {"latent": -9.545454545454545}, {"latent": -9.393939393939394}, {"latent": -9.242424242424242}, {"latent": -9.09090909090909}, {"latent": -8.93939393939394}, {"latent": -8.787878787878787}, {"latent": -8.636363636363637}, {"latent": -8.484848484848484}, {"latent": -8.333333333333334}, {"latent": -8.181818181818182}, {"latent": -8.030303030303031}, {"latent": -7.878787878787879}, {"latent": -7.727272727272727}, {"latent": -7.575757575757576}, {"latent": -7.424242424242424}, {"latent": -7.2727272727272725}, {"latent": -7.121212121212121}, {"latent": -6.96969696969697}, {"latent": -6.818181818181818}, {"latent": -6.666666666666666}, {"latent": -6.515151515151516}, {"latent": -6.363636363636363}, {"latent": -6.212121212121212}, {"latent": -6.0606060606060606}, {"latent": -5.909090909090909}, {"latent": -5.757575757575758}, {"latent": -5.6060606060606055}, {"latent": -5.454545454545454}, {"latent": -5.303030303030303}, {"latent": -5.151515151515151}, {"latent": -5.0}, {"latent": -4.848484848484849}, {"latent": -4.696969696969697}, {"latent": -4.545454545454545}, {"latent": -4.393939393939394}, {"latent": -4.242424242424242}, {"latent": -4.090909090909091}, {"latent": -3.9393939393939394}, {"latent": -3.787878787878788}, {"latent": -3.636363636363636}, {"latent": -3.4848484848484844}, {"latent": -3.333333333333333}, {"latent": -3.1818181818181817}, {"latent": -3.0303030303030303}, {"latent": -2.878787878787879}, {"latent": -2.7272727272727266}, {"latent": -2.5757575757575752}, {"latent": -2.424242424242424}, {"latent": -2.2727272727272725}, {"latent": -2.121212121212121}, {"latent": -1.9696969696969688}, {"latent": -1.8181818181818183}, {"latent": -1.666666666666666}, {"latent": -1.5151515151515156}, {"latent": -1.3636363636363633}, {"latent": -1.212121212121211}, {"latent": -1.0606060606060606}, {"latent": -0.9090909090909083}, {"latent": -0.7575757575757578}, {"latent": -0.6060606060606055}, {"latent": -0.45454545454545503}, {"latent": -0.30303030303030276}, {"latent": -0.1515151515151505}, {"latent": 0.0}, {"latent": 0.15151515151515227}, {"latent": 0.30303030303030276}, {"latent": 0.45454545454545503}, {"latent": 0.6060606060606055}, {"latent": 0.7575757575757578}, {"latent": 0.9090909090909101}, {"latent": 1.0606060606060606}, {"latent": 1.2121212121212128}, {"latent": 1.3636363636363633}, {"latent": 1.5151515151515156}, {"latent": 1.6666666666666679}, {"latent": 1.8181818181818183}, {"latent": 1.9696969696969706}, {"latent": 2.121212121212121}, {"latent": 2.2727272727272734}, {"latent": 2.424242424242424}, {"latent": 2.575757575757576}, {"latent": 2.7272727272727284}, {"latent": 2.878787878787879}, {"latent": 3.030303030303031}, {"latent": 3.1818181818181817}, {"latent": 3.333333333333334}, {"latent": 3.4848484848484844}, {"latent": 3.6363636363636367}, {"latent": 3.787878787878789}, {"latent": 3.9393939393939394}, {"latent": 4.090909090909092}, {"latent": 4.242424242424242}, {"latent": 4.3939393939393945}, {"latent": 4.545454545454547}, {"latent": 4.696969696969697}, {"latent": 4.8484848484848495}, {"latent": 5.0}]}}, {"mode": "vega-lite"});
</script></div>
</div>
</section>
<section id="Fitting-procedure">
<h2>Fitting procedure<a class="headerlink" href="#Fitting-procedure" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">multidms</span></code> software package has a framework for fitting free parameters in the model given input DMS data. The mathematical model is coded in <a class="reference external" href="https://www.python.org/">Python</a> using the <a class="reference external" href="https://github.com/google/jax">JAX library</a> <a class="footnote-reference brackets" href="#footcite-jax2018github" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> allowing for autograd and XLA compilation for high-performance optimization. We approach our non-smooth optimization problem via proximal gradient descent in order to satisfy several simultaneous constraints such as L1
regularization, optionally locking parameters, and clipping parameters at pre-specified lower bounds. Specifically, we use <a class="reference external" href="https://jaxopt.github.io/stable/index.html">JAXopt</a> to optimize parameters via full-batch proximal gradient descent using the <a class="reference external" href="https://jaxopt.github.io/stable/_autosummary/jaxopt.ProximalGradient.html">JAXopt.ProximalGradient</a> function.</p>
<p>We now define notation and introduce our model more formally to describe the fitting procedure without ambiguity. Let <span class="math notranslate nohighlight">\(M\in\mathbb{N}\)</span> denote the number of distinct mutations, and represent a given variant <span class="math notranslate nohighlight">\(v\subset\mathcal{M}\equiv\{1,\dots,M\}\)</span> as an index set of the mutations it contains (<span class="math notranslate nohighlight">\(v\)</span> is in the set of subsets of the <span class="math notranslate nohighlight">\(M\)</span> mutations, i.e. <span class="math notranslate nohighlight">\(v\in\mathcal{V}\equiv2^\mathcal{M}\)</span>, where <span class="math notranslate nohighlight">\(2^\mathcal{M}\)</span> denotes the power set of <span class="math notranslate nohighlight">\(\mathcal{M}\)</span>).</p>
<p>Consider a variant <span class="math notranslate nohighlight">\(v\)</span> as an indicator (one-hot) vector <span class="math notranslate nohighlight">\(x_v\in\{0,1\}^M\)</span> where <span class="math notranslate nohighlight">\(\left[x_v\right]_i=1\)</span> if <span class="math notranslate nohighlight">\(i\in v\)</span> and <span class="math notranslate nohighlight">\(\left[x_v\right]_i=0\)</span> otherwise. Let <span class="math notranslate nohighlight">\(D\in\mathbb{N}\)</span> be the number of experiments and write <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> for the <span class="math notranslate nohighlight">\(D\)</span>-vector of ones (the letter <span class="math notranslate nohighlight">\(D\)</span> is used as a mnemonic for DMS). We introduce an additive <em>latent phenotype</em> model jointly for <span class="math notranslate nohighlight">\(D\)</span> experiments via a family of affine maps
<span class="math notranslate nohighlight">\(\phi_{(\beta_0,\beta,\Delta)}:\{0, 1\}^M\to\mathbb{R}^D\)</span> defined by</p>
<div class="math notranslate nohighlight">
\[\phi_{(\beta_0,\beta,\Delta)}(x) = \beta_0\mathbf{1} + (\mathbf{1}\beta^\intercal + \Delta) x, \quad x\in\{0, 1\}^M,\]</div>
<p>where the family is parameterized by intercept <span class="math notranslate nohighlight">\(\beta_0\in\mathbb{R}\)</span> and mutational effects <span class="math notranslate nohighlight">\(\beta\in\mathbb{R}^M\)</span> that are shared by all <span class="math notranslate nohighlight">\(D\)</span> output dimensions, and shift matrix <span class="math notranslate nohighlight">\(\Delta\in\mathbb{R}^{D\times M}\)</span>. We require that the first row of <span class="math notranslate nohighlight">\(\Delta\)</span> is the zero <span class="math notranslate nohighlight">\(M\)</span>-vector, so that the reference experiment (indexed 1 WLOG) has no shifts, and <span class="math notranslate nohighlight">\(\beta\)</span> is then interpreted as the vector of mutational effects in the reference experiment, with the
intercept <span class="math notranslate nohighlight">\(\beta_0\)</span> representing the latent phenotype of the wildtype sequence in the reference experiment.</p>
<p>Next, we introduce a <em>global-epistasis function</em> via a family of strictly monotone maps <span class="math notranslate nohighlight">\(g_\theta:\mathbb{R}\to\mathbb{R}\)</span> that we use to take latent phenotypes to predicted functional scores. This family is parameterized by <span class="math notranslate nohighlight">\(\theta\in\mathbb{R}^r\)</span> for some <span class="math notranslate nohighlight">\(r\in\mathbb{N}\)</span>. By default, <code class="docutils literal notranslate"><span class="pre">multidms</span></code> will use the sigmoid function</p>
<div class="math notranslate nohighlight">
\[g_\theta(z) = \theta_0 + \frac{\theta_1}{1+e^{-z}}, \quad z\in\mathbb{R},\]</div>
<p>with <span class="math notranslate nohighlight">\(r=2\)</span> parameters, which allows us to adapt the output range of the global-epistasis function (the interval <span class="math notranslate nohighlight">\((\theta_0, \theta_0 + \theta_1)\)</span>) to the range of our functional score data, but is otherwise a fixed link function (imposing a <em>gauge</em> on our latent phenotype model parameters). We finally compute the predicted functional score in experiment <span class="math notranslate nohighlight">\(d\in\{1,\dots,D\}\)</span> of a variant <span class="math notranslate nohighlight">\(v\in\mathcal{V}\)</span> with one-hot encoding <span class="math notranslate nohighlight">\(x_v\in\{0, 1\}^M\)</span> as</p>
<div class="math notranslate nohighlight">
\[\hat{y}_d(x_v) = g_\theta\left(\left[\phi_{(\beta_0,\beta,\Delta)}(x_v)\right]_d\right).\]</div>
<p>Our data consists of sets of one-hot encoded variants and their associated functional scores from each of <span class="math notranslate nohighlight">\(D\)</span> experiments. Denote these as <span class="math notranslate nohighlight">\(\mathcal{D}_d \subset \{0, 1\}^M\times\mathbb{R}\)</span> for <span class="math notranslate nohighlight">\(d=1,\dots,D\)</span>. We minimize an objective of the form:</p>
<div class="math notranslate nohighlight">
\[f(\beta_0,\beta,\Delta,\theta) = \sum_{d=1}^D\sum_{(x, y)\in\mathcal{D}_d}\!\!\ell(y,\hat{y}_d(x)) + \lambda\|\Delta\|_{1,1},\]</div>
<p>where <span class="math notranslate nohighlight">\(\ell:\mathbb{R}\times\mathbb{R}\to\mathbb{R}\)</span> is a Huber loss function measuring the difference between a predicted and an observed functional score, <span class="math notranslate nohighlight">\(\lambda\in\mathbb{R}\)</span> is the lasso penalty weight, and <span class="math notranslate nohighlight">\(\|\cdot\|_{1,1}\)</span> denotes the entrywise <span class="math notranslate nohighlight">\(L_1\)</span> norm (not to be confused with the matrix 1-norm <span class="math notranslate nohighlight">\(\|\cdot\|_1\)</span>). Note that the parameters <span class="math notranslate nohighlight">\((\beta_0,\beta,\Delta,\theta)\)</span> appear in the loss function via the predicted functional score equation, but are
suppressed in the objective for notational compactness. Note also that, by taking <span class="math notranslate nohighlight">\(\lambda=0\)</span>, the loss term of the objective becomes separable over the <span class="math notranslate nohighlight">\(D\)</span> experiments, so marginal inference is recovered as a special case.</p>
<p>For a general global epistasis function <span class="math notranslate nohighlight">\(g_\theta\)</span>, the objective is in general non-convex. However, with the simple sigmoid function, it is bi-convex in <span class="math notranslate nohighlight">\((\beta_0, \beta, \Delta)\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>. This can be seen by noting that, for fixed <span class="math notranslate nohighlight">\(\theta\)</span>, the prediction model takes the form of a generalized linear model with a sigmoid link function, and for fixed <span class="math notranslate nohighlight">\((\beta_0, \beta, \Delta)\)</span>, the model parameterized by <span class="math notranslate nohighlight">\(\theta\)</span> is a linear regression problem. We
optimize the objective using the Nesterov-accelerated proximal gradient method with backtracking line search <a class="footnote-reference brackets" href="#footcite-beck2009fast" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this heading"></a></h2>
</section>
</section>
<div class="docutils container" id="id5">
<aside class="footnote brackets" id="footcite-hastie2015lasso" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Trevor Hastie, Robert Tibshirani, and Martin Wainwright. <em>Statistical Learning with Sparsity: The Lasso and Generalizations</em>. Chapman &amp; Hall/CRC, 2015. ISBN 1498712169.</p>
</aside>
<aside class="footnote brackets" id="footcite-otwinowski2018globalepistasis" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Jakub Otwinowski, David M. McCandlish, and Joshua B. Plotkin. Inferring the shape of global epistasis. <em>Proceedings of the National Academy of Sciences</em>, 115(32):E7550–E7558, 2018. URL: <a class="reference external" href="https://www.pnas.org/doi/abs/10.1073/pnas.1804015115">https://www.pnas.org/doi/abs/10.1073/pnas.1804015115</a>, <a class="reference external" href="https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.1804015115">arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.1804015115</a>, <a class="reference external" href="https://doi.org/10.1073/pnas.1804015115">doi:10.1073/pnas.1804015115</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-jax2018github" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs. <em>SysML</em>, 2018. URL: <a class="reference external" href="http://github.com/google/jax">http://github.com/google/jax</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-beck2009fast" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. <em>SIAM journal on imaging sciences</em>, 2(1):183–202, 2009.</p>
</aside>
</aside>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/2020-logo-1000px-transparent.png" alt="Logo"/>
    
    <h1 class="logo logo-name">multidms</h1>
    
  </a>
</p>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=matsengrp&repo=multidms&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">multidms documentation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Biophysical model</a></li>
<li class="toctree-l1"><a class="reference internal" href="fit_delta_BA1_example.html"><code class="docutils literal notranslate"><span class="pre">multidms</span></code> fitting pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="multidms.html">multidms package</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgments.html">Acknowledgments</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="installation.html" title="previous chapter">Installation</a></li>
      <li>Next: <a href="fit_delta_BA1_example.html" title="next chapter"><code class="docutils literal notranslate"><span class="pre">multidms</span></code> fitting pipeline</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Jared Galloway, Hugh Haddox.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/biophysical_model.nblink.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>