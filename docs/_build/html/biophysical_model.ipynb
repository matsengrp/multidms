{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0db34cc",
   "metadata": {},
   "source": [
    "# Biophysical model\n",
    "\n",
    "The `multidms` joint model applies primarily to a case where you have DMS datasets\n",
    "for two or more experimental conditions and are interested in identifying shifts\n",
    "in mutational effects between conditions. \n",
    "Here we describe the biophysical model of conditional shifts that motivates the approach in this package.\n",
    "\n",
    "We suggest reading the [Otwinowski et al. 2018](https://www.pnas.org/doi/10.1073/pnas.1804015115) paper to understand the approach for modeling global epistasis before reading the rest of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f510168f",
   "metadata": {},
   "source": [
    "## Model overview\n",
    "\n",
    "`multidms` extends the traditional global epistasis model by informing the parameters with multiple dms experiments under differing experimental conditions. For example, distinct experimental conditions (referred to as $h$ throughout the documentation) may include sets of experiments that are performed with differing homology of wildtype sequence (i.e. SARS-CoV-2 Delta Vs. Omicron spike). This approach could also be used for experimental conditions which share homology of the wildtype, but are run with different selection targets. This model makes the assumption that differing conditions should result in _mostly_ the same effect of mutations -- but some _shifts_ in mutational effect due to biological mechanisms (i.e. epistasis). Ultimately, this model was designed to identify those shifts using feature selection via $L1$ regularization of the shift parameters described in the additive latent phenotype section below.\n",
    "\n",
    "[//]: # \"We find that the qualitative results are robust to choice for lasso strength, and generally this lasso\"\n",
    "[//]: # \"acts as a single dial to increase signal and noise in a linear fasion\"\n",
    "\n",
    "\n",
    "At a high level, the model is a composition of three\n",
    "functions which describe the expected biophysical interactions underlying a given phenotype;\n",
    "(1) an additive model, $\\phi$, describing a variant's _latent_ phenotype under a given condition,\n",
    "(2) a global epistasis model, $g$, to disentangle the effects of multiple mutations on the same variant, and\n",
    "(3) a final output activation function, $t$, accounting for an expected _lower bound_ on the variant's phenotype,\n",
    "where the observed functional score may sit below due to experimental sensitivity.\n",
    "\n",
    "Concretely, the predicted phenotype for a given variant $v$ under condition $h$ is given by \n",
    "\n",
    "$$\n",
    "\\hat{y}_{v,h} = t_{\\gamma}(g_{\\alpha}(\\phi_{\\beta, S, C_{r}}(v,h))\n",
    "$$\n",
    "\n",
    "Where \n",
    "$\\gamma$, $\\alpha$, $\\beta$, $S$, and $C_{r}$\n",
    "are _free_ parameters inferred from experimental observations during the fitting process.\n",
    "\n",
    "**Note** The motivation behind defining an abstract model in terms of its components offers us (1) modularity for method testing and development, and (2) The flexibility of multiple options for model components that encompass the needs of differing research goals and experimental techniques. While there is only a single option for the $\\phi$ latent prediction, we offer a few options both for the global epistasis ($g$) and output activation ($t$) functions. Generally, the package defaults for these components described below should be sufficient for most purposes, and in this case feel free to ignore the `multidms.biophysical` module all-together as this functionality is generally hidden unless explicitly specified during the instantiation of a `MultiDmsModel` object. \n",
    "\n",
    "Below, we'll describe the individual components in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bae88f",
   "metadata": {},
   "source": [
    "## Normalizing observed functional scores using $\\gamma_{h}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85660ad",
   "metadata": {},
   "source": [
    "The first consideration is whether observed functional scores are directly comparable between conditions.\n",
    "In context of the model, _Predicted_ functional scores are all directly comparable since all are generated from the same latent space via the same global-epistasis function.\n",
    "However, observed scores may not be comparable in the same way.\n",
    "For instance, a common way to compute functional scores is with log enrichment ratios, normalized so that the wildtype sequence has a value of zero.\n",
    "If the conditions being compared are DMS experiments conducted in the background of different homologs, then each homolog will necessarily have a functional score of zero within its experiment, even if those same homologs would have different functional scores when measured in the same experiment.\n",
    "Thus, log enrichment ratios are not always directly comparable between experiments.\n",
    "Ideally one or more of the same sequences would be included in the experimental design of DMS libraries to be compared, so that all scores can be normalized to the same sequence.\n",
    "However, if there are no such sequences, then it may be possible to computationally estimate how to renormalize scores.\n",
    "\n",
    "To this end, the model includes an additional parameter $\\gamma_h$ for each non-reference condition that allows functional scores, $y'_{v,h}$ from that condition to be renormalized as follows:\n",
    "\n",
    "$$\n",
    "y'_{v,h} = y_{v,h} + \\gamma_h\n",
    "$$\n",
    "\n",
    "where $\\gamma_h$ for the reference condition is locked at zero.\n",
    "There is a theoretical basis for adding $\\gamma_h$ to $y_{v,h}$ if functional scores are log enrichment ratios.\n",
    "As mentioned above, log enrichment ratios are normalized so that the wildtype sequence from a given experiment has a value of zero, according to the formula:\n",
    "\n",
    "$$\n",
    "y_{v,h} = \\log(E_{v,h}) - \\log(E_{\\text{wt},h})\n",
    "$$\n",
    "\n",
    "Thus, adding $\\gamma_d$ to $y_{v,d}$ is akin to renormalizing the log enrichment ratios so that a different sequence has a functional score of zero.\n",
    "In theory, for each non-reference condition, there is a $\\gamma_d$ that renormalizes functional scores to be relative to the wildtype sequence of the reference condition.\n",
    "If these values are not experimentally measured, the model allows $\\gamma_d$ parameters to be fit during optimization, which assumes that the correct $\\gamma_d$ values will give the best model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967d19d",
   "metadata": {},
   "source": [
    "## Additive latent phenotype, $\\phi$\n",
    "\n",
    "The model defines one condition as a _reference_ condition.\n",
    "For each mutation $m$, the model fits a single mutation effect parameter, $\\beta_{m}$.\n",
    "Additionally, the model fits set of shift parameters, $S_{m,h}$, \n",
    "that quantifies the shift a given mutation's\n",
    "effect. Each mutation is associated with an independent shift parameter \n",
    "for each non-reference condition. \n",
    "For example if there exists 3 total experimental conditions, $h_{1}$, $h_{2}$, & $h_{3}$, \n",
    "then each mutation, $m$, will be get assigned a\n",
    "single $\\beta_{m}$ parameter, \n",
    "and two non-reference condition _shift_ parameters $S_{m, h_{2}}$, $S_{m, h_{3}}$ for the latent prediction\n",
    "\n",
    "Shift parameters can be regularized, encouraging most of them to be\n",
    "close to zero. This regularization step is a useful way to eliminate\n",
    "the effects of experimental noise, and is most useful in cases where\n",
    "you expect most mutations to have the same effects between conditions,\n",
    "such as for conditions that are close relatives. \n",
    "\n",
    "Concretely, the latent phenotype of any variant, $v$, from the experimental condition, $h$,\n",
    "is computed like so:\n",
    "\n",
    "$$\n",
    "\\phi(v,h) = c_{r} + \\sum_{m \\in v} (\\beta_{m} + S_{m,h})\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $c_{r}$ is the wild type latent phenotype for the reference condition.\n",
    "* $\\beta_{m}$ is the latent phenotypic effect of mutation $m$. See the note below\n",
    "* $s_{m,h}$ is the shift of the effect of mutation $m$ in condition $h$.\n",
    "  These parameters are fixed to zero for the reference condition. For\n",
    "  non-reference conditions, they are defined in the same way as $\\beta_m$ parameters.\n",
    "* $v$ is the set of all mutations relative to the reference wild type sequence\n",
    "  (including all mutations that separate condition $h$ from the reference condition).\n",
    "\n",
    "**Note** The $\\beta_m$ variable is defined such that mutations are always relative to the\n",
    "reference condition. For example, if the wild type amino acid at site 30 is an\n",
    "A in the reference condition, and a G in a non-reference condition,\n",
    "then a Y30G mutation in the non-reference condition is recorded as an A30G\n",
    "mutation relative to the reference. This way, each condition informs\n",
    "the exact same parameters, even at sites that differ in wild type amino acid.\n",
    "These are encoded in a `BinaryMap` object, where all sites that are non-identical\n",
    "to the reference are 1's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8613ea",
   "metadata": {},
   "source": [
    "## global epistasis, $g$\n",
    "\n",
    "Latent phenotypes as described above give rise to functional scores according to a global-epistasis function.\n",
    "If this function is non-linear, then the model allows mutations to non-additively effect functional scores, helping to account for global epistasis.\n",
    "Here, we'll go into more detail about the options available in `multidms` \n",
    "\n",
    "### Sigmoidal:\n",
    "\n",
    "By default, the global-epistasis function here assumes a sigmoidal relationship between\n",
    "a protein's latent property and it's functional score measured in the experiment\n",
    "(e.g., log enrichment score). Using free parameters, the sigmoid\n",
    "can flexibly conform to an optimal shape informed by the data. \n",
    "Note that this function is independent from the\n",
    "experimental condition from which a variant is observed.\n",
    "\n",
    "The sigmoidal function that relates a given _latent phenotype_, $z$, to its functional score is given by:\n",
    "\n",
    "$$\n",
    "g(z) =  \\frac{\\alpha_{scale}}{1 + e^{-z}} + \\alpha_{bias}\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $\\alpha_{scale}$ is a free parameter defining the range of the sigmoid\n",
    "* $\\alpha_{bias}$ is a free parameter defining the lower bound of the sigmoid.\n",
    "\n",
    "Below is an interactive plot showing the effect of the sigmoidal global epistasis as a function of an adjustable $\\alpha_{scale}$, and $\\alpha_{bias}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3e310c",
   "metadata": {
    "hideCode": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-a8413d12bb834e8484698cc55c08d6d7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a8413d12bb834e8484698cc55c08d6d7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a8413d12bb834e8484698cc55c08d6d7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-5df0d8288b8899ccb5d4c64cc03b51be\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"latent phenotype\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"alpha_scale\", \"bind\": {\"input\": \"range\", \"max\": 10, \"min\": 0.1}, \"value\": 1}, {\"name\": \"alpha_bias\", \"bind\": {\"input\": \"range\", \"max\": 5, \"min\": -10}, \"value\": 0}], \"transform\": [{\"calculate\": \"(((1 / (1 + exp((-1 * datum['latent'])))) * alpha_scale) + alpha_bias)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-5df0d8288b8899ccb5d4c64cc03b51be\": [{\"latent\": -10.0}, {\"latent\": -9.797979797979798}, {\"latent\": -9.595959595959595}, {\"latent\": -9.393939393939394}, {\"latent\": -9.191919191919192}, {\"latent\": -8.98989898989899}, {\"latent\": -8.787878787878787}, {\"latent\": -8.585858585858587}, {\"latent\": -8.383838383838384}, {\"latent\": -8.181818181818182}, {\"latent\": -7.979797979797979}, {\"latent\": -7.777777777777778}, {\"latent\": -7.575757575757576}, {\"latent\": -7.373737373737374}, {\"latent\": -7.171717171717171}, {\"latent\": -6.96969696969697}, {\"latent\": -6.767676767676768}, {\"latent\": -6.565656565656566}, {\"latent\": -6.363636363636363}, {\"latent\": -6.161616161616162}, {\"latent\": -5.959595959595959}, {\"latent\": -5.757575757575758}, {\"latent\": -5.555555555555555}, {\"latent\": -5.353535353535354}, {\"latent\": -5.151515151515151}, {\"latent\": -4.94949494949495}, {\"latent\": -4.747474747474747}, {\"latent\": -4.545454545454546}, {\"latent\": -4.343434343434343}, {\"latent\": -4.141414141414142}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.737373737373738}, {\"latent\": -3.5353535353535355}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1313131313131315}, {\"latent\": -2.929292929292929}, {\"latent\": -2.7272727272727275}, {\"latent\": -2.525252525252525}, {\"latent\": -2.3232323232323235}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9191919191919187}, {\"latent\": -1.717171717171718}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3131313131313131}, {\"latent\": -1.1111111111111107}, {\"latent\": -0.9090909090909101}, {\"latent\": -0.7070707070707076}, {\"latent\": -0.5050505050505052}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.10101010101010033}, {\"latent\": 0.10101010101010033}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.5050505050505052}, {\"latent\": 0.7070707070707076}, {\"latent\": 0.9090909090909083}, {\"latent\": 1.1111111111111107}, {\"latent\": 1.3131313131313131}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.7171717171717162}, {\"latent\": 1.9191919191919187}, {\"latent\": 2.121212121212121}, {\"latent\": 2.3232323232323235}, {\"latent\": 2.525252525252524}, {\"latent\": 2.7272727272727266}, {\"latent\": 2.929292929292929}, {\"latent\": 3.1313131313131315}, {\"latent\": 3.333333333333334}, {\"latent\": 3.5353535353535346}, {\"latent\": 3.737373737373737}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.141414141414142}, {\"latent\": 4.3434343434343425}, {\"latent\": 4.545454545454545}, {\"latent\": 4.747474747474747}, {\"latent\": 4.94949494949495}, {\"latent\": 5.1515151515151505}, {\"latent\": 5.353535353535353}, {\"latent\": 5.555555555555555}, {\"latent\": 5.757575757575758}, {\"latent\": 5.9595959595959584}, {\"latent\": 6.161616161616163}, {\"latent\": 6.363636363636363}, {\"latent\": 6.565656565656564}, {\"latent\": 6.767676767676768}, {\"latent\": 6.969696969696969}, {\"latent\": 7.171717171717173}, {\"latent\": 7.373737373737374}, {\"latent\": 7.575757575757574}, {\"latent\": 7.777777777777779}, {\"latent\": 7.979797979797979}, {\"latent\": 8.18181818181818}, {\"latent\": 8.383838383838384}, {\"latent\": 8.585858585858585}, {\"latent\": 8.787878787878789}, {\"latent\": 8.98989898989899}, {\"latent\": 9.19191919191919}, {\"latent\": 9.393939393939394}, {\"latent\": 9.595959595959595}, {\"latent\": 9.7979797979798}, {\"latent\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 10, 100)})\n",
    "\n",
    "slider_s = alt.binding_range(min=0.1, max=10)\n",
    "var_s = alt.param(bind=slider_s, value=1, name=\"alpha_scale\")\n",
    "\n",
    "slider_b = alt.binding_range(min=-10, max=5)\n",
    "var_b = alt.param(bind=slider_b, value=0, name=\"alpha_bias\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=(1 / (1 + alt.expr.exp(-1*alt.datum['latent'])))\n",
    "        * var_s\n",
    "        + var_b\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"latent phenotype\", scale=alt.Scale(domain=[-10, 10])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 10]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_s, var_b)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f20abb",
   "metadata": {},
   "source": [
    "### Single layer neural network epistasis:\n",
    "\n",
    "If you prefer a less constrained shape for global epistasis, we also offer the ability to learn the shape of global epistasis using a single layer neural network. For this option, the user defines a number of units in the singular hidden layer of the model. For each hidden unit, we introduce three free parameters (2 weights and a bias). All weights are clipped at zero to maintain assumptions of monotonicity in the resulting epistasis function shape.  The network applies a sigmoid activation to each internal unit before a final transformation and addition of a constant gives us our predicted functional score. \n",
    "\n",
    "Given a latent phenotype, z, the neural network function can then be defined:\n",
    "\n",
    "$$\n",
    "g(z) = b^{o}+ \\sum_{i}^{n}(\\frac{w^{o}_{i}}{1 + e^{w^{l}_{i}*z + b^{l}_{i}}})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $n$ is the number of units in the hidden layer\n",
    "* $w^{l}_{i}$, $w^{o}_{i}$ are free parameters associated with the pre and post tranformations of unit $i$ in the hidden layer of the network\n",
    "* $b^{l}_{i}$ is a vector of free parameters of length n\n",
    "* $b^{o}$ is a constant, singular free parameter\n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function `multidms.biophysical.single_layer_nn`\n",
    "\n",
    "### Identity (no epistasis):\n",
    "\n",
    "In some scenerios, deep mutational scanning data only contains single-mutation variants to be observed. It then becomes hopeless to learn anything useful about epiststatic effects. In this scenerio, we provide the option to functionally disable any global epistsis modeling by setting $g(z) = z$. \n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function definition `multidms.biophysical.identity_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2732d9",
   "metadata": {},
   "source": [
    "## Output activation, $t$\n",
    "\n",
    "The commonly reported fold-change functional score metric falls victim to the limits of detection of a given experiment to provide an accurate ratio when the starting frequency of a barcoded variant is low. Common solutions to this sensitivity problem include the use of highly multiplexed assays with variant-level barcode replicates, as well simply filtering out low frequency variants. Unfortunatly, even modest filtering thresholds for starting frequency and number of barcode replicates may cut out important data. \n",
    "\n",
    "Thus, it's also common for researchers to simply _truncate_ (i.e. _clip_) the functional at some lower bound $l$, where observations below are assumed largely to be artifacts of experimental sensitivity. In practice, this truncation helps to reduce the impact of outliers on the model's performance.\n",
    "\n",
    "This clipping leads to unwanted behavior in our global epistasis model. Put simply, the model, $g(\\phi(v,h))$ _learns_ this lower bound and thus is encouraged to limit it's shape to conform to this lower bound. This behavior is particularly problematic when normalizing the observed functional scores with $\\gamma_{h}$, described above. To provide intuition, consider a scenario where observed functional scores are truncated at a lower bound of -3 across all conditions. If $\\gamma_d$ is fit to -1.0 for one of the non-reference conditions, then the new floor of functional scores will be -4 for that condition, while the floor for the reference condition would still be -3.\n",
    "In this case, the global epistasis function could find itself in a pickle: if it allows predictions to go below -3, it could help model the floor of points in the non-reference condition, but hurt with modeling the floor of points in the reference condition.\n",
    "\n",
    "### Softplus\n",
    "\n",
    "By default, we avoid this unwanted behavior by applying a final activation on the output of the global epistasis model $g(\\phi(v,h))$. In essence, this is a modified _softplus_ activation, ($\\text{softplus}(x)=\\log(1 + e^{x})$) with a _lower bound_ at $l + \\gamma_{h}$, as well as a _ramping_ coefficient, $\\lambda_{\\text{sp}}$. \n",
    "\n",
    "Concretely, if we let $z' = g(\\phi(v,h))$, then the predicted functional score of our model is given by:\n",
    "\n",
    "$$\n",
    "t(z') = \\lambda_{sp}\\log(1 + e^{\\frac{z' - l}{\\lambda_{sp}}}) + l\n",
    "$$\n",
    "\n",
    "Functionally speaking, this truncates scores below a lower bound, while leaving scores above (mostly) unaltered. There is a small range of input values where the function smoothly transitions between a flat regime (where data is truncated) and a linear regime (where data is not truncated). \n",
    "\n",
    "**Note** By default, we recommend leaving the $\\lambda_{sp}$ parameter at it's default value of $0.1$. this ensures a sharp transition between regimes similar to a [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) function, but retain the differentible property for gradient based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d03fe",
   "metadata": {},
   "source": [
    "Below is an interactive plot showing the effect of the modified softplus activation as a function of an adjustable $\\lambda_{sp}$ scaling parameter, and lower bound, $l$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02d0f67",
   "metadata": {
    "hideCode": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-72fba78112734383afc6f82aa5cefc54\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-72fba78112734383afc6f82aa5cefc54\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-72fba78112734383afc6f82aa5cefc54\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.6.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.6.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-5df0d8288b8899ccb5d4c64cc03b51be\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"latent\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"global epistasis prediction (z')\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"phenotype\", \"scale\": {\"domain\": [-10, 10]}, \"title\": \"predicted phenotype\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"lambda_sp\", \"bind\": {\"input\": \"range\", \"max\": 10, \"min\": 0.1}, \"value\": 1}, {\"name\": \"lower_bound\", \"bind\": {\"input\": \"range\", \"max\": 0, \"min\": -10}, \"value\": -3.5}], \"transform\": [{\"calculate\": \"((log((1 + exp(((datum['latent'] - lower_bound) / lambda_sp)))) * lambda_sp) + lower_bound)\", \"as\": \"phenotype\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.6.1.json\", \"datasets\": {\"data-5df0d8288b8899ccb5d4c64cc03b51be\": [{\"latent\": -10.0}, {\"latent\": -9.797979797979798}, {\"latent\": -9.595959595959595}, {\"latent\": -9.393939393939394}, {\"latent\": -9.191919191919192}, {\"latent\": -8.98989898989899}, {\"latent\": -8.787878787878787}, {\"latent\": -8.585858585858587}, {\"latent\": -8.383838383838384}, {\"latent\": -8.181818181818182}, {\"latent\": -7.979797979797979}, {\"latent\": -7.777777777777778}, {\"latent\": -7.575757575757576}, {\"latent\": -7.373737373737374}, {\"latent\": -7.171717171717171}, {\"latent\": -6.96969696969697}, {\"latent\": -6.767676767676768}, {\"latent\": -6.565656565656566}, {\"latent\": -6.363636363636363}, {\"latent\": -6.161616161616162}, {\"latent\": -5.959595959595959}, {\"latent\": -5.757575757575758}, {\"latent\": -5.555555555555555}, {\"latent\": -5.353535353535354}, {\"latent\": -5.151515151515151}, {\"latent\": -4.94949494949495}, {\"latent\": -4.747474747474747}, {\"latent\": -4.545454545454546}, {\"latent\": -4.343434343434343}, {\"latent\": -4.141414141414142}, {\"latent\": -3.9393939393939394}, {\"latent\": -3.737373737373738}, {\"latent\": -3.5353535353535355}, {\"latent\": -3.333333333333333}, {\"latent\": -3.1313131313131315}, {\"latent\": -2.929292929292929}, {\"latent\": -2.7272727272727275}, {\"latent\": -2.525252525252525}, {\"latent\": -2.3232323232323235}, {\"latent\": -2.121212121212121}, {\"latent\": -1.9191919191919187}, {\"latent\": -1.717171717171718}, {\"latent\": -1.5151515151515156}, {\"latent\": -1.3131313131313131}, {\"latent\": -1.1111111111111107}, {\"latent\": -0.9090909090909101}, {\"latent\": -0.7070707070707076}, {\"latent\": -0.5050505050505052}, {\"latent\": -0.30303030303030276}, {\"latent\": -0.10101010101010033}, {\"latent\": 0.10101010101010033}, {\"latent\": 0.30303030303030276}, {\"latent\": 0.5050505050505052}, {\"latent\": 0.7070707070707076}, {\"latent\": 0.9090909090909083}, {\"latent\": 1.1111111111111107}, {\"latent\": 1.3131313131313131}, {\"latent\": 1.5151515151515156}, {\"latent\": 1.7171717171717162}, {\"latent\": 1.9191919191919187}, {\"latent\": 2.121212121212121}, {\"latent\": 2.3232323232323235}, {\"latent\": 2.525252525252524}, {\"latent\": 2.7272727272727266}, {\"latent\": 2.929292929292929}, {\"latent\": 3.1313131313131315}, {\"latent\": 3.333333333333334}, {\"latent\": 3.5353535353535346}, {\"latent\": 3.737373737373737}, {\"latent\": 3.9393939393939394}, {\"latent\": 4.141414141414142}, {\"latent\": 4.3434343434343425}, {\"latent\": 4.545454545454545}, {\"latent\": 4.747474747474747}, {\"latent\": 4.94949494949495}, {\"latent\": 5.1515151515151505}, {\"latent\": 5.353535353535353}, {\"latent\": 5.555555555555555}, {\"latent\": 5.757575757575758}, {\"latent\": 5.9595959595959584}, {\"latent\": 6.161616161616163}, {\"latent\": 6.363636363636363}, {\"latent\": 6.565656565656564}, {\"latent\": 6.767676767676768}, {\"latent\": 6.969696969696969}, {\"latent\": 7.171717171717173}, {\"latent\": 7.373737373737374}, {\"latent\": 7.575757575757574}, {\"latent\": 7.777777777777779}, {\"latent\": 7.979797979797979}, {\"latent\": 8.18181818181818}, {\"latent\": 8.383838383838384}, {\"latent\": 8.585858585858585}, {\"latent\": 8.787878787878789}, {\"latent\": 8.98989898989899}, {\"latent\": 9.19191919191919}, {\"latent\": 9.393939393939394}, {\"latent\": 9.595959595959595}, {\"latent\": 9.7979797979798}, {\"latent\": 10.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"latent\": numpy.linspace(-10, 10, 100)})\n",
    "\n",
    "slider_lsp = alt.binding_range(min=0.1, max=10)\n",
    "var_lambda_sp = alt.param(bind=slider_lsp, value=1, name=\"lambda_sp\")\n",
    "\n",
    "slider_lb = alt.binding_range(min=-10, max=0)\n",
    "var_lower_bound = alt.param(bind=slider_lb, value=-3.5, name=\"lower_bound\")\n",
    "\n",
    "(\n",
    "    alt.Chart(df)\n",
    "    .transform_calculate(\n",
    "        phenotype=alt.expr.log(1 + alt.expr.exp((alt.datum['latent']-var_lower_bound)/var_lambda_sp))\n",
    "        * var_lambda_sp\n",
    "        + var_lower_bound\n",
    "    )\n",
    "    .encode(\n",
    "        x=alt.X(\"latent\", title=\"global epistasis prediction (z')\", scale=alt.Scale(domain=[-10, 10])),\n",
    "        y=alt.Y(\"phenotype:Q\", title=\"predicted phenotype\", scale=alt.Scale(domain=[-10, 10]))\n",
    "    )\n",
    "    .mark_line()\n",
    "    .add_params(var_lambda_sp, var_lower_bound)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867183d",
   "metadata": {},
   "source": [
    "### Identity (no activation):\n",
    "\n",
    "We offer the option to functionally _disable_ this feature incase there's no expected floor on the range of fitting data.\n",
    "\n",
    "**Note** In the `multidms` API, This is accomplished by setting the \"output_activation\" parameter in the constructor for `MultiDmsModel` to be a pointer to the function definition `multidms.biophysical.identity_activation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc52e5",
   "metadata": {},
   "source": [
    "## Fitting procedure\n",
    "\n",
    "`multidms` is implimented in _python_ using the [JAX](https://github.com/google/jax) library\n",
    "allowing for the direct differentiation of the model functions.\n",
    "The [jaxopt](https://jaxopt.github.io/stable/index.html) package is used for effecient optimization of all parameters with proximal gradient descent.\n",
    "Given DMS training data, The objective is to minimize the difference between _normalized observed_ and _predected_ functional scores ($y'_{v, h} - \\hat{y}$). We apply a lasso ($l^{1}$) penalty to all $s_{v,h}$ parameters for feature selection of high confidence values, and encouraging the rest to be $0$.\n",
    "\n",
    "The total loss on a dataset is computed as the sum of the individual losses for each condition in the dataset. \n",
    "\n",
    "$$\n",
    "L_{\\text{total}} = \\sum_{h} [L_{\\text{fit},h} + L_{\\text{reg},h}]\n",
    "$$\n",
    "\n",
    "conditional loss is then given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L_{\\text{fit},h} &= \\frac{\\sum_{v} L_{\\text{Huber}}(y'_{v,h}, t(v,h))}{n_h} \\\\\n",
    "L_{\\text{reg},h} &= \\lambda \\sum_{m} |s_{m,h}|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $L_{\\text{Huber}}$ is a Huber loss function and \n",
    "* $n_{n}$ is the number of variants in the condition.\n",
    "\n",
    "Dividing the numerator $L_{\\text{fit},h}$ by $n_d$ makes it so that $L_{\\text{fit},d}$ returns the average loss across all variants. Ultimitely, this ensures that each condition contributes equally to $L_\\text{total}$, regardless of the number of variants in that condition.\n",
    "\n",
    "**Note** We find the qualitative results of model fits and their respective shift parameters are quite robust for a reasonable choice of $\\lambda$ applied to the lasso. In other words, this parameter can be set to reflect the user's own preference for [accuracy-simplicity](https://en.wikipedia.org/wiki/Lasso_(statistics)) tradeoff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
